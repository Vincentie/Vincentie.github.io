<!DOCTYPE html><html xmlns:v-bind="http://www.w3.org/1999/xhtml"><head><meta name="generator" content="Hexo 3.9.0"><title>post - Avalon</title><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="John Reese"><meta name="description" content="1. Intro to FIQT - Eurodollar FuturesConvexity Adjustment..."><meta name="keywords" content><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0" name="viewport"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><meta name="theme-color" content="#ffffff"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous"><link rel="stylesheet" href="/css/journal.css?27215793"><script src="/js/loadCSS.js"></script><script>loadCSS("https://fonts.googleapis.com/css?family=Lora|Montserrat|Fira+Mono|Material+Icons"),function(e){var t,a={kitId:"dwg1tuc",scriptTimeout:3e3,async:!0},o=e.documentElement,s=setTimeout(function(){o.className=o.className.replace(/\bwf-loading\b/g,"")+" wf-inactive"},a.scriptTimeout),c=e.createElement("script"),i=!1,n=e.getElementsByTagName("script")[0];o.className+=" wf-loading",c.src="https://use.typekit.net/"+a.kitId+".js",c.async=!0,c.onload=c.onreadystatechange=function(){if(t=this.readyState,!(i||t&&"complete"!=t&&"loaded"!=t)){i=!0,clearTimeout(s);try{Typekit.load(a)}catch(e){}}},n.parentNode.insertBefore(c,n)}(document)</script><noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora|Montserrat|Anonymous+Pro:400|Material+Icons"></noscript><link rel="stylesheet" href="/css/prism.css" type="text/css"></head><body><div id="top"></div><div id="app"><div class="single-column-drawer-container" ref="drawer" v-bind:class="{ 'single-column-drawer-container-active': isDrawerOpen }"><div class="drawer-content"><div class="drawer-menu"><a class="a-block drawer-menu-item false" href="http://yoursite.com">Home </a><a class="a-block drawer-menu-item false" href="/archives">記事一覽 </a><a class="a-block drawer-menu-item false" href="/about/index.html">關於我 </a><a class="a-block drawer-menu-item false" href="/categories/index.html">分類 </a><a class="a-block drawer-menu-item false" href="/tags/index.html">標簽</a></div></div></div><transition name="fade"><div v-bind:class="{ 'single-column-drawer-mask': mounted }" v-if="isDrawerOpen" v-on:click="toggleDrawer"></div></transition><nav ref="navBar" class="navbar sticky-top navbar-light single-column-nav-container"><div ref="navBackground" class="nav-background"></div><div class="container container-narrow nav-content"><button id="nav_dropdown_btn" class="nav-dropdown-toggle" type="button" v-on:click="toggleDrawer"><i class="material-icons">menu</i></button> <a ref="navTitle" class="navbar-brand" href="/">Avalon</a></div></nav><div class="single-column-header-container" ref="pageHead" v-bind:style="{ transform: 'translateZ(0px) translateY('+.3*scrollY+'px)', opacity: 1-navOpacity }"><a href="/"><div class="single-column-header-title">Avalon</div><div class="single-column-header-subtitle">Welcome!!</div></a></div><div ref="sideContainer" class="side-container"><a class="a-block nav-head false" href="/"><div class="nav-title">远い理想郷</div><div class="nav-subtitle">お帰りなさい</div></a><div class="nav-link-list"><a class="a-block no-tint nav-link-item false" href="/archives">記事一覽 </a><a class="a-block nav-link-item false" href="/about/index.html">關於我 </a><a class="a-block nav-link-item false" href="/categories/index.html">分類 </a><a class="a-block nav-link-item false" href="/tags/index.html">標簽</a></div><div class="nav-footer">Proudly published with Hexo<br>Theme <a href="https://github.com/SumiMakito/hexo-theme-journal/" target="_blank" rel="noreferrer noopener">Journal.</a> by <a href="https://mak1t0.cc/" target="_blank" rel="noreferrer noopener">Makito</a><br>&copy; 2020 <a href="http://yoursite.com">Avalon</a></div></div><div ref="extraContainer" class="extra-container"><div class="pagination"><a id="globalBackToTop" class="pagination-action animated-visibility" href="#top" :class="{ invisible: scrollY == 0 }"><i class="material-icons pagination-action-icon">keyboard_arrow_up</i></a></div></div><div ref="streamContainer" class="stream-container"><div class="post-list-container post-list-container-shadow"><div class="post"><div class="post-head-wrapper-text-only" style="background-image:url('')"><div class="post-title">post<div class="post-meta"><time datetime="2019-08-19T15:25:41.000Z" itemprop="datePublished">2019-08-19 11:25 </time>&nbsp;</div></div></div><div class="post-body-wrapper"><div class="post-body"><h2 id="intro-to-fiqt---eurodollar-futures">1. Intro to FIQT - Eurodollar Futures</h2><h4 id="convexity-adjustment">Convexity Adjustment</h4><p>(A time scope grapsh is needed here...)</p><p>There exists a convexity adjustment between LIBOR forward contracts and Eurodollar futures. Hos is this derived is shown below</p><p>Assume <span class="math inline">\(\delta(t, T)\)</span> is the forward price at time <span class="math inline">\(t\)</span> which expires at time <span class="math inline">\(T\)</span>, and <span class="math inline">\(L(T)\)</span> is the LIBOR rate at time <span class="math inline">\(T\)</span>, <span class="math inline">\(r(t)\)</span> is the risk-free rate process. We can easily know the rational price of zero coupon bond at time <span class="math inline">\(t\)</span> which expires at time <span class="math inline">\(T\)</span>, or <span class="math inline">\(T\)</span>-forward numeraire is <span class="math display">\[ p(t, T) = E_t^Q[e^{-\int_{t}^{T}r(u)du}]\]</span></p><p>For a LIBOR forward <strong>contract</strong> that was entered at time <span class="math inline">\(t\)</span>, its contact value is 0, which is $$ <span class="math display">\[\begin{equation} \begin{aligned} 0 &amp; = E_t^Q \left[ e^{-\int_{t}^{T}r(u)du} [\delta(t, T) - L(T)] \right] \\ &amp; = E_t^{Q}\left[ e^{-\int_{t}^{T}r(u)du} \delta(t, T) - e^{-\int_{t}^{T}r(u)du} L(T)\right]\\ &amp; = E_t^{Q}\left[ e^{-\int_{t}^{T}r(u)du} \delta(t, T) \right] - E_t^{Q}\left[ e^{-\int_{t}^{T}r(u)du} \right] E_t^Q [L(T)] - cov \left( e^{-\int_{t}^{T}r(u)du}, L(T) \right) \\ &amp; = \delta(t, T) \cdot p(t, T) - p(t, T) \cdot E_t^Q [L(T)] - cov \left( e^{-\int_{t}^{T}r(u)du}, L(T) \right)\\ \end{aligned} \end{equation}\]</span> <span class="math display">\[ where we apply the covriance equation $cov(X, Y) = E[X Y] - E[X] E[Y]$, so we have \]</span>(t, T) = E_t^Q [L(T)] + cov ( e^{-_{t}^{T}r(u)du}, L(T) )$$</p><h4 id="npv-effect">NPV Effect</h4><p>Consider the value of a forward contract at <span class="math inline">\(t&#39; &gt; t\)</span> under CSA, a contract that was entered at time <span class="math inline">\(t\)</span>, so the difference in contract values on <span class="math inline">\(t&#39;\)</span> and <span class="math inline">\(t\)</span> that exchanges hands at <span class="math inline">\(t&#39;\)</span> is equal to <span class="math display">\[ V(t&#39;) - V(t) = E_{t&#39;} \left( e^{-\int_{t&#39;}^{T}r_c(u)du} \right) (F_{CSA}(t&#39;, T) - F_{CSA}(t, T)) \]</span> while the difference of futures contract will not be discounted, which is <span class="math display">\[ F(t&#39;) - F(t) = F_{CSA}(t&#39;, T) - F_{CSA}(t, T) \]</span></p><p>Let's take a look at another example in Pieterbarg(2010)</p><h2 id="historical-factor-model">2. Historical Factor Model</h2><h4 id="canonical-component-anaylsis">Canonical Component Anaylsis</h4><p>Let's first look at a question: Here is a risk report for 2 underlying yield sensitivity (Position sensitivity) { 10yr yield sensitivity: - 100k / bp { 30yr yield sensitivity: + 100k / bp So How do we hedge this risk?</p><p>The most common thing one can think of is oridinal leaset regression. The problem with this method is that the in-sample regression relationship will easily break out of sample. ** There should be an example snippet.** However we have more pratical method to find the hedge ratio. And this is where CCA should be introduced.</p><p>Say there is a pair of cmt rates - (<span class="math inline">\(Y_t^1\)</span>, <span class="math inline">\(Y_t^2\)</span>), what we are trying to do is find a coitegration vector to let the following equation stand</p><p><span class="math display">\[ Y_t^1 - \gamma \cdot Y_t^2 = \mu + \epsilon_t\]</span></p><p>where <span class="math inline">\(\epsilon_t\)</span> is a stationary white noise process.</p><p>What if we extend a pair to a portfolio consisting of more than n cmt rates <span class="math inline">\(Y_t = [Y_t^1, Y_t^2, ..., Y_t^n]^T\)</span>? The problem also focusing on find a coitegration vector <span class="math inline">\(\gamma = [\gamma_1, \gamma_2, ..., \gamma_n]^T\)</span> to let the following equation stand</p><p><span class="math display">\[ \gamma^T Y_t = \mu + \epsilon_t\]</span></p><p>Theoretically, we can find a cointegration vector to build a mean-reverting time series among as many assets as we want. But in practice, it's hard to execute them all with proper prices at one time, and the execution costs are also very high.</p><p>There is also one thing to know - Will regression with different order yield different sets of cointegration vectors? <strong>Seems like the cointegration vectors are the same.</strong> (<strong>Formula and derivation needed.</strong>)</p><p>Let's look at how CCA is rigorously derived. There are 2 similar ways of performing CCA - one is introduced in <a href="https://" target="_blank" rel="noopener">Box-Tiao(1977)</a> and another is introduced in <a href="https://" target="_blank" rel="noopener">Chou and Ng(19xx)</a>.</p><p>Consider a $1 k $ vector process <span class="math inline">\(\{\mathbb{Z_t}\}\)</span> and let <span class="math inline">\(z_t = \mathbb{Z_t} - \mu\)</span>, where <span class="math inline">\(\mu\)</span> is a convenient <span class="math inline">\(1 \times k\)</span> vector of origin which is the mean if the process is stationary. Suppose <span class="math inline">\(z_t\)</span> follows the <em>p</em>th order multiple autoregressive model</p><p><span class="math display">\[z_t = \hat z_{t-1}(1) + a_t\]</span></p><p>where</p><p><span class="math display">\[\hat z_{t-1}(1) = E(z_t|z_{t-1}, z_{t-2},..) = \sum_{l=1}^{p}z_{t-l} \pi_l\]</span></p><p>is the expectation of <span class="math inline">\(z_t\)</span> conditional on past history up to time <span class="math inline">\(t-1\)</span>, the <span class="math inline">\(\pi_l\)</span> are <span class="math inline">\(k \times k\)</span> matrices, <span class="math inline">\(\{ a_t\}\)</span> is a sequence of independtly and normally distributed <span class="math inline">\(1 \times k\)</span> vector random shocks with mean zero and covariance matrix <span class="math inline">\(\Sigma\)</span>, and <span class="math inline">\(a_t\)</span> is independent of <span class="math inline">\(\hat z_{t-1}(1)\)</span> - like the assumptions in OLS. And the <span class="math inline">\(AR(p)\)</span> model can be then represented as</p><p><span class="math display">\[z_t (I - \sum_{l=1}^{p}\pi_l B^l) = a_t\]</span></p><p>where <span class="math inline">\(I\)</span> is the identity matrix and <span class="math inline">\(B\)</span> is the backshift operator such that <span class="math inline">\(B z_t = z_{t-1}\)</span>.</p><p>The process <span class="math inline">\(\{z_t\}\)</span> is stationary if the determinantal polynomial in <span class="math inline">\(B\)</span>, <span class="math inline">\(det(I - \sum_{l=1}^{p}\pi_l B^l)\)</span> has its zeros lying outside the unit circle(<strong>?? recall AR(1) has its coef &lt; 1</strong>), and otherwise the process will be called non-stationary.</p><p>Now, let's make the problem simpler by setting <span class="math inline">\(k=1\)</span> to narrow down to only 1 time series. Then, if the process is stationary (<strong>if not, can we still derive this?</strong> - look back on stationary's condtions), due to <span class="math inline">\(a_t\)</span> being independent of <span class="math inline">\(\hat z_{t-1}(1)\)</span>.</p><p><span class="math display">\[E(z_t^2) = E(\{\hat z_{t-1}(1)\}^2) + E(a_t^2)\]</span></p><p>which can be also written as</p><p><span class="math display">\[ \sigma_z^2 = \sigma_{\hat z}^2 + \sigma_a^2\]</span></p><p>We can then define a quantity <span class="math inline">\(\lambda\)</span> to measure the predictability of a stationary series from its past as <span class="math inline">\(\lambda = \frac{\sigma_{\hat z}^2}{\sigma_z^2} = 1 - \frac{\sigma_a^2}{\sigma_z^2}\)</span>. <strong>Note</strong>: the derivation above only applies to 1 time series.</p><h4 id="intuition">Intuition</h4><p>Now let's go back to the <span class="math inline">\(k \times 1\)</span> vector, and we can think of these <span class="math inline">\(k\)</span> processes represent <span class="math inline">\(k\)</span> diffrent stock market index such as <em>Dow Jones Average</em>, <em>Standard and Poors</em> and <em>Russell Index</em>, etc., all of which exhibit dynamic growth. It is natural to conjecture that <strong>each</strong> might be represented as some aggregate of one or more common inputs which may be nearly nonstationary (<strong>momentum</strong>), together with other stationary(<strong>mean-reverting</strong>) or white noise components.</p><p><strong>Here is the trick.</strong> It leads to a natrual contemplate linear aggregates of the form $u_t = z_t m $, where <span class="math inline">\(m\)</span> is the cononical matrix whose column are such vectors that <strong>make <span class="math inline">\(u_t\)</span> a multi time series consiting of momentum and mean-reverting time series.</strong></p><p>And we call these time series <strong>aggregates</strong>. The aggregates which depend most heavily on the past, namely having large <span class="math inline">\(\lambda\)</span> (<span class="math inline">\(\lambda\)</span> here refers to <span class="math inline">\(u_t\)</span>'s <span class="math inline">\(\lambda\)</span>), may serve as useful composite indicators of the overall growth of the stock market (<strong>momentum</strong>). By contrast, the aggregates with <span class="math inline">\(\lambda\)</span> nearly zero may reflect stable contemporaneous relationships (<strong>mean-reverting</strong>) among the orignal indicators.</p><p>The analysis given in this paper yields <span class="math inline">\(k\)</span> 'conancial' components from laest to most predictable. Thus we may usefully decompose the k-dimensional space of the observation <span class="math inline">\(z_t\)</span> into stationary and non-stationary subspaces.</p><h4 id="derive-canonical-variables">Derive Canonical Variables</h4><p>Let <span class="math inline">\(\Gamma_j(z) = E(z_t^T z_{t-j})\)</span> be the lag <span class="math inline">\(j\)</span> autocovariance matrix of <span class="math inline">\(z_t\)</span>. In the variance form, we have (<strong>the first '=' needs to be proved further.</strong>)</p><p><span class="math display">\[ \Gamma_0(z) = \sum_{l=1}^{p} \Gamma_l(z)\pi_l + \Sigma= \Gamma_0(\hat z) + \Sigma \]</span></p><p>say, where <span class="math inline">\(\Gamma_0(\hat z)\)</span> is the covariance matrix of <span class="math inline">\(\hat z_{t-1}(1)\)</span>. <strong>Until further notice, we shall assume that <span class="math inline">\(\Sigma\)</span> and therefore <span class="math inline">\(\Gamma_0(z)\)</span> are postive-defnite.</strong></p><p>Now, consider the linear combination <span class="math inline">\(u_t = z_t m\)</span>. For <span class="math inline">\(u_t\)</span>, we have that <span class="math inline">\(u_t = \hat u_{t-1}(1) + v_t\)</span>, where <span class="math inline">\(\hat u_{t-1}(1) = \hat z_{t-1}(1) m\)</span> and <span class="math inline">\(v_t=a_t m\)</span>. The predictability of <span class="math inline">\(u_t\)</span> from its past is therefore measured by</p><p><span class="math display">\[ \lambda = \sigma_{\hat u}^2 \sigma_{u}^{-2} = \{ m \Gamma_{0}(\hat z) m^T \} \{m \Gamma_{0}(z) m^T \}^{-1}\]</span></p><p>which can be represented in matrix form as</p><p><span class="math display">\[ \Lambda = M \Gamma_{0}(\hat z) \Gamma_{0}^{-1}(z) M^{-1}\]</span></p><p>(Note: M is what we are looking for. The logic is we want to find a transformed process <span class="math inline">\(\{u_t\}\)</span> which is generated by <span class="math inline">\(M\)</span> and the original <span class="math inline">\(z_t\)</span>. And we derive that M can be found using eigenvector decmoposition of <span class="math inline">\(???\)</span>.)</p><p>This is what we call eigen vector decomposition, and therefore we can conclude that for the maximum predictability, <span class="math inline">\(\lambda\)</span> must be the eigenvalue of <span class="math inline">\(\Gamma_{0}(\hat z) \Gamma_{0}^{-1}(z)\)</span> and <span class="math inline">\(m\)</span> the corresponding eigenvector that makes <span class="math inline">\(u_t\)</span> a momentum time series. Similarly, the eigenvector that corresponds to the smallest eigenvalue will yield the least predictable combination of <span class="math inline">\(z_t\)</span>. <strong>This vector is referred to as coitegration vector</strong> that is mainly used in the first question (risk hedging) mentioned at the very beginning.</p><h3 id="conanical-transformation">Conanical Transformation</h3><p>This chapter is a bit like PCA transformation.</p><p>Let <span class="math inline">\(\lambda_1, ..., \lambda_k\)</span> be the k real eigenvalues of matrix <span class="math inline">\(\Gamma_{0}(\hat z) \Gamma_{0}^{-1}(z)\)</span>. Supposed <span class="math inline">\(\lambda_j\)</span> are ordered with <span class="math inline">\(\lambda_1\)</span> the smallest, and that the k corresponding linearly independent eigenvectors, <span class="math inline">\(m_1, .., m_k\)</span> from the k columns of a matrix <span class="math inline">\(M\)</span>. Then, we can construct a transformed process <span class="math inline">\(\{ y_t\}\)</span>, where</p><p><span class="math display">\[y_t = \hat y_{t-1} (1) + b_t\]</span></p><p>with</p><p><span class="math display">\[y_t = z_t M, b_t = a_t M, \hat y_{t-1}(1)=\sum_{l=1}^{p} y_{t-l}\pi^1_l, \pi^1_l=M^{-1} \pi_l M ???\]</span></p><p>We now also have</p><p><span class="math display">\[\Gamma_0(y) = \Gamma_0(\hat y) + \Sigma^1\]</span></p><p>where <span class="math inline">\(\Gamma_0(y)=M \Gamma_0(z)M^T, \Gamma_0(\hat y)=M \Gamma_0(\hat z)M^T, \Sigma^1=M \Sigma M^T\)</span></p><p>Note: - $ M <em>{0}(z) </em>{0}^{-1}(z) M^{-1} = , M _{0}^{-1}(z) M^{-1} = I - $ where <span class="math inline">\(\Lambda\)</span> is a <span class="math inline">\(k \times k\)</span> matrix with elements <span class="math inline">\((\lambda_1, .., \lambda_k)\)</span> - <span class="math inline">\(0 \leq \lambda_j &lt; 1 \space (j=1,..,k)\)</span> - This makes <span class="math inline">\(M \Sigma M^T, M \Gamma_0(\hat z) M^T, M \Gamma_0(z) M^T\)</span> are all diagnoal (easy to prove).</p><p>With this diagonal propery, we can conclude that this transformation has produced <span class="math inline">\(k\)</span> components series <span class="math inline">\(\{ y_{1t}, y_{2t}, .., y_{kt}\}\)</span> which are</p><ul><li>ordered from least predictable to most predictable</li><li>are contemporaneously independent</li><li>have predictable components <span class="math inline">\(\{\hat y_{1(t-1)}(1), y_{2(t-1)}(1), .., y_{k(t-1)}(1)\}\)</span> which are also contemporaneously independent</li><li>the same goes for <span class="math inline">\(\{ b_{1t}, b_{2t}, .., b_{kt}\}\)</span></li></ul><p><strong>Note</strong>: The content above goes for general time series, and the content below goes for AR(1) time series.(Also <span class="math inline">\(M\)</span> above can be computed in another way.)</p><p>Application 1. Spot small mean-reverting portfolios. 2. CCA decomposition to generate detrended data.</p><p>(<strong>Snippets Needed</strong>)</p><h2 id="term-structure-model">3. Term Structure Model</h2><h2 id="tsm-fitting">4. TSM fitting</h2><h2 id="signal-research-framework">5. Signal Research Framework</h2><h2 id="livie-eurodollar-futures-trading">6. Livie Eurodollar Futures Trading</h2></div></div><nav class="post-pagination"><a class="newer-posts" href="/2019/10/20/CCA/">Previous post<br>Canonical Component Analysis </a><span class="page-number"></span> <a class="older-posts" href="/2019/07/30/post/">Next post<br>电影的尽头是电影共产主义</a></nav></div></div><div class="single-column-footer">Proudly published with Hexo<br>Theme <a href="https://github.com/SumiMakito/hexo-theme-journal/" target="_blank" rel="noreferrer noopener">Journal.</a> by <a href="https://mak1t0.cc/" target="_blank" rel="noreferrer noopener">Makito</a><br>&copy; 2020 <a href="http://yoursite.com">Avalon</a></div></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.14.4/dist/umd/popper.min.js" integrity="sha256-EGs9T1xMHdvM1geM8jPpoo8EZ1V1VRsmcJz8OByENLA=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/vue@2.5.17/dist/vue.min.js" integrity="sha256-FtWfRI+thWlNz2sB3SJbwKx5PgMyKIVgwHCTwa3biXc=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/smooth-scroll@14.2.1/dist/smooth-scroll.polyfills.min.js" integrity="sha256-CI4Gq5E0io1Pv0xM3qPM+NUIOhbIBvC3GiN1Y4KhXpw=" crossorigin="anonymous"></script><script src="/js/journal.js?84966202"></script></body></html>
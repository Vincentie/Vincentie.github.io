<!DOCTYPE html><html xmlns:v-bind="http://www.w3.org/1999/xhtml"><head><meta name="generator" content="Hexo 3.9.0"><title>A Mysterious Algorithm used in Apollo 11 Guidance - Avalon</title><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="John Reese"><meta name="description" content="Some Notes on State Space Models and Kalman Filtering"><meta name="keywords" content><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0" name="viewport"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><meta name="theme-color" content="#ffffff"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous"><link rel="stylesheet" href="/css/journal.css?51136145"><script src="/js/loadCSS.js"></script><script>loadCSS("https://fonts.googleapis.com/css?family=Lora|Montserrat|Fira+Mono|Material+Icons"),function(e){var t,a={kitId:"dwg1tuc",scriptTimeout:3e3,async:!0},o=e.documentElement,s=setTimeout(function(){o.className=o.className.replace(/\bwf-loading\b/g,"")+" wf-inactive"},a.scriptTimeout),c=e.createElement("script"),i=!1,n=e.getElementsByTagName("script")[0];o.className+=" wf-loading",c.src="https://use.typekit.net/"+a.kitId+".js",c.async=!0,c.onload=c.onreadystatechange=function(){if(t=this.readyState,!(i||t&&"complete"!=t&&"loaded"!=t)){i=!0,clearTimeout(s);try{Typekit.load(a)}catch(e){}}},n.parentNode.insertBefore(c,n)}(document)</script><noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora|Montserrat|Anonymous+Pro:400|Material+Icons"></noscript><link rel="stylesheet" href="/css/prism.css" type="text/css"></head><body><div id="top"></div><div id="app"><div class="single-column-drawer-container" ref="drawer" v-bind:class="{ 'single-column-drawer-container-active': isDrawerOpen }"><div class="drawer-content"><div class="drawer-menu"><a class="a-block drawer-menu-item false" href="http://yoursite.com">Home </a><a class="a-block drawer-menu-item false" href="/archives">記事一覽 </a><a class="a-block drawer-menu-item false" href="/about/index.html">關於我 </a><a class="a-block drawer-menu-item false" href="/categories/index.html">分類 </a><a class="a-block drawer-menu-item false" href="/tags/index.html">標簽</a></div></div></div><transition name="fade"><div v-bind:class="{ 'single-column-drawer-mask': mounted }" v-if="isDrawerOpen" v-on:click="toggleDrawer"></div></transition><nav ref="navBar" class="navbar sticky-top navbar-light single-column-nav-container"><div ref="navBackground" class="nav-background"></div><div class="container container-narrow nav-content"><button id="nav_dropdown_btn" class="nav-dropdown-toggle" type="button" v-on:click="toggleDrawer"><i class="material-icons">menu</i></button> <a ref="navTitle" class="navbar-brand" href="/">Avalon</a></div></nav><div class="single-column-header-container" ref="pageHead" v-bind:style="{ transform: 'translateZ(0px) translateY('+.3*scrollY+'px)', opacity: 1-navOpacity }"><a href="/"><div class="single-column-header-title">Avalon</div><div class="single-column-header-subtitle">Welcome!!</div></a></div><div ref="sideContainer" class="side-container"><a class="a-block nav-head false" href="/"><div class="nav-title">远い理想郷</div><div class="nav-subtitle">お帰りなさい</div></a><div class="nav-link-list"><a class="a-block no-tint nav-link-item false" href="/archives">記事一覽 </a><a class="a-block nav-link-item false" href="/about/index.html">關於我 </a><a class="a-block nav-link-item false" href="/categories/index.html">分類 </a><a class="a-block nav-link-item false" href="/tags/index.html">標簽</a></div><div class="nav-footer">Proudly published with Hexo<br>Theme <a href="https://github.com/SumiMakito/hexo-theme-journal/" target="_blank" rel="noreferrer noopener">Journal.</a> by <a href="https://mak1t0.cc/" target="_blank" rel="noreferrer noopener">Makito</a><br>&copy; 2020 <a href="http://yoursite.com">Avalon</a></div></div><div ref="extraContainer" class="extra-container"><div class="pagination"><a id="globalBackToTop" class="pagination-action animated-visibility" href="#top" :class="{ invisible: scrollY == 0 }"><i class="material-icons pagination-action-icon">keyboard_arrow_up</i></a></div></div><div ref="streamContainer" class="stream-container"><div class="post-list-container post-list-container-shadow"><div class="post"><div class="post-head-wrapper" style="background-image:url(/2020/04/23/kalman-filter/kf_cover.png)"><div class="post-title">A Mysterious Algorithm used in Apollo 11 Guidance<div class="post-meta"><time datetime="2020-04-24T01:05:54.000Z" itemprop="datePublished">2020-04-23 21:05 </time>&nbsp; <i class="material-icons">folder</i> <a href="/categories/Quant/">Quant</a></div></div></div><div class="post-body-wrapper"><div class="post-body"><h2 id="Kalman-Filter"><a href="#Kalman-Filter" class="headerlink" title="Kalman Filter"></a>Kalman Filter</h2><h3 id="0-State-Space-Models"><a href="#0-State-Space-Models" class="headerlink" title="0. State Space Models"></a>0. State Space Models</h3><p>In <a href="https://en.wikipedia.org/wiki/State-space_representation#Example:_continuous-time_LTI_case" target="_blank" rel="noopener">Wikipedia</a>, a state space model is described as a set of input, output and state variables mixed with some ODE systems. I have no idea what that is with this abstract definition. State variables</p><p>can also be known as hidden states evolving through time in a way that we don’t know how but we would like to use some <strong>dynamics</strong> and <strong>observations</strong> to fit the evolution path.</p><p><strong>An Example</strong></p><p>Let’s look at a random walk example below,</p><p>Say we model some hidden states with two parts, which are its last state and some random noise. Also, we give the mapping relationship from $x_k$ to $z_k$ as below.<br>$$<br>x_k = x_{k - 1} + w_{k - 1}, w_{k} \sim N(0, Q),<br>$$</p><p>$$<br>z_k = x_k + \epsilon_{k}, \epsilon_{k} \sim N(0, R),<br>$$</p><p>where $x_k$ is the state variable and $z_k$ is the observation value, and $w_{k}$, $\epsilon_{k}$ are independent normal random noise.</p><p><img src="random_walk.png" alt="Random walk"></p><p>Basically, we have a state space model about $x_k$, and we would like to know how exactly $x_k$ will evolve in future steps. From the equations above, we can also estimate $\hat x_k$ with current $\hat x_{k - 1}$ and $z_{k-1}$.</p><p><strong>Probabilistic State Space Models</strong></p><p>But usually, a point estimate is less significant than an interval estimate. So here comes Probabilistic State Space Models.</p><p>With the same example above, we can know the distribution of $x_k$ given $x_{k-1}$and the distribution of observations $z_k$ given $x_{k}$.<br>$$<br>p(x_k | x_{k - 1}) = \frac{1}{\sqrt{2 \pi Q}}\exp \left( -\frac{1}{2Q}(x_k - x_{k - 1})^2 \right)<br>$$</p><p>$$<br>p(z_k | x_{k}) = \frac{1}{\sqrt{2 \pi R}}\exp \left( -\frac{1}{2R}(z_k - x_{k})^2 \right)<br>$$</p><p>where $p(\cdot)$ represents a probability density function.</p><p><strong>Assumptions</strong></p><p>Typically, we use $p(x_k | x_{k - 1})$ instead of $p(x_k | x_{1},x_{2},…,x_{k - 1})$ to describe the conditional distribution is due to the Markovian assumption, which is <strong>future states are independent from the past states given the present.</strong><br>$$<br>p(x_k | x_{k - 1}) = p(x_k | x_{1},x_{2},…,x_{k - 1}, z_{1},z_{2},…,z_{k - 1})<br>$$<br>Also, we can also naturally think of the relationship between states and observations. Obviously, <strong>observations only depend on its current states</strong> instead of past observations or past states.<br>$$<br>p(z_k | x_{k}) = p(z_k | x_{1},x_{2},…,x_{k}, z_{1},z_{2},…,z_{k - 1})<br>$$<br>Simpler forms of these assumptions are as below<br>$$<br>p(x_k | x_{1:k-1}, z_{1:k}) = p(x_k | x_{k - 1})<br>$$</p><p>$$<br>p(z_k | x_{1:k}, z_{1:k - 1}) = p(z_k | x_{k})<br>$$</p><h3 id="1-Bayesian-Filter"><a href="#1-Bayesian-Filter" class="headerlink" title="1. Bayesian Filter"></a>1. Bayesian Filter</h3><p>From <a href="https://en.wikipedia.org/wiki/Bayesian_inference" target="_blank" rel="noopener">Bayesian inference</a>, the probability for an event is updated as more evidence or information becomes available, so we would like to use Bayes rules to <strong>simulate</strong> the probability distribution of hidden states $x_t$ with incoming observations.<br>$$<br>\begin{align<em>}<br>p(x_k |z_{1:k}) &amp;= \frac{p(x_k, z_{1:k})}{p( z_{1:k})}\<br>&amp;= \frac{p(z_k | z_{1:k-1}, x_k) p(x_k |z_{1:k-1}) p(z_{1:k-1})}{p(z_{1:k})}\<br>&amp;= \eta p(z_k | x_k) p(x_k | z_{1:k-1}), \space where \space\space \eta = p(z_k | z_{1:k-1})\<br>&amp;= \eta p(z_k | x_k) \int{p(x_k | x_{k-1}, z_{1:k-1})p(x_{k-1} | z_{1:k-1})dx_{k-1}}\<br>&amp;= \eta p(z_k | x_k) \int{p(x_k | x_{k-1})p(x_{k-1} | z_{1:k-1})dx_{k-1}}\<br>\end{align</em>}<br>$$<br>Here comes a recursion formula if we replace $p(x_k |u_{1:k})$ with $Bel(x_k)$ meaning the posterior pdf of $x_k$ at time $k$, so we have<br>$$<br>Bel(x_k) = \eta p(z_k|x_k) \int p(x_k|x_{k-1})Bel(x_{k-1})dx_{k-1}<br>$$<br>where $p(z_k|x_k)$ and $p(x_k|x_{k-1})$ correspond exactly to the 2 hypothetical equations discussed in the random walk example, which are <strong>Observations-States Mapping</strong> and <strong>State Dynamics</strong>. Intuitively, we need state dynamics to make apriori estimates ($\int{p(x_k | x_{k-1})p(x_{k-1} | z_{1:k-1})dx_{k-1}}$) and observations to make likelihood adjustments, thus making the Bayesian rules complete. <a href="https://users.aalto.fi/~ssarkka/course_k2016/handout3.pdf#page=12" target="_blank" rel="noopener">Here</a> shows how the distribution of $x_{k}$ evolves under Bayesian rules.</p><p><strong>A New Input</strong></p><p>Now we introduce another control variable ${u_t}$ which may serve as an additional impact to $x_k$, and we can now imagine the state model has the new form like below:<br>$$<br>x_k = x_{k - 1} + u_{k} + w_{k - 1}, w_{k} \sim N(0, Q),<br>$$</p><p>$$<br>z_k = x_k + \epsilon_{k}, \epsilon_{k} \sim N(0, R),<br>$$</p><p>Also, we cast those 2 assumptions to $u_k$, then we have<br>$$<br>p(x_k | x_{1:k-1}, u_{1:k}, z_{1:k}) = p(x_k | x_{k - 1}, u_k)<br>$$</p><p>$$<br>p(z_k | x_{1:k}, u_{1:k}, z_{:k - 1}) = p(z_k | x_{k})<br>$$</p><p>The target conditional probability distribution has now become posterior distribution $p(x_k | u_{1:k}, z_{1:k})$, we would like to know how the current state behaves given the most recent series of observations and control variables.<br>$$<br>\begin{align<em>}<br>p(x_k |u_{1:k}, z_{1:k}) &amp;= \frac{p(x_k, u_{1:k}, z_{1:k})}{p(u_{1:k}, z_{1:k})}\<br>&amp;= \frac{p(z_k | u_{1:k}, z_{1:k-1}, x_k) p(x_k | u_{1:k}, z_{1:k-1}) p(u_{1:k}, z_{1:k-1})}{p(u_{1:k}, z_{1:k})}\<br>&amp;= \eta p(z_k | x_k) p(x_k | u_{1:k}, z_{1:k-1}), \space where \space\space \eta = p(z_k | u_{1:k}, z_{1:k-1})\<br>&amp;= \eta p(z_k | x_k) \int{p(x_k | x_{k-1}, u_{1:k}, z_{1:k-1})p(x_{k-1} | u_{1:k}, z_{1:k-1})dx_{k-1}}\<br>&amp;= \eta p(z_k | x_k) \int{p(x_k | x_{k-1}, u_k)p(x_{k-1} | u_{1:k-1}, z_{1:k-1})dx_{k-1}}\<br>\end{align</em>}<br>$$<br>Here comes a recursion formula if we replace $p(x_k |u_{1:k}, z_{1:k})$ with $Bel(x_k)$ meaning the posterior pdf of $x_k$ at time $k$, so we have<br>$$<br>Bel(x_k) = \eta p(z_k|x_k) \int p(x_k|x_{k-1},u_k)Bel(x_{k-1})dx_{k-1}<br>$$<br>which is all the same as the previous formula except $u_k$. Now we can separate this recursion formula into two parts<br>$$<br>\overline {Bel}{(x_k)} = \int p(x_k|x_{k-1},u_k)Bel(x_{k-1})dx_{k-1}<br>$$</p><p>$$<br>Bel(x_k) = \eta p(z_k|x_k)\overline {Bel}{(x_k)}<br>$$</p><p>state prediction and state update respectively. We can say $x_k$ is predicted with new inputs of control variables $u_k$ and updated with corresponding observations $z_k$.</p><p>Why we need a new input $u_k$? Simply speaking, we need some other factors rather than pure past states to explain the evolution of $x_k$. To be more specific, Bayesian filter is widely used in probabilistic robotics where there is always robotics control (say robots are controlled to move 2 meters ahead) and the control itself influences a system’s state (the state is the position of the robot).</p><h3 id="2-Kalman-Filter"><a href="#2-Kalman-Filter" class="headerlink" title="2. Kalman Filter"></a>2. Kalman Filter</h3><p>The recursion equation above indicates how the distribution of $x_k$ evolves through time. However we do not know what is the exact distribution of $x_{k-1}$ given a random initial distribution $x_0$. If an initial random distribution is given, then we must follow the recursion formula to integrate over all possible $x_{k-1}$ to get an estimate.</p><p>Here comes the trick of Kalman Filter-using <strong>Gaussian</strong> distributions to describe $x_k$. Because linear combinations of Gaussian distributions are still Gaussian, the states distribution evolution is easier to follow under Gaussian assumptions.</p><p><strong>Assumptions</strong></p><ol><li>State Dynamics and Observation-State Mapping are both linear models:</li></ol><p>$$<br>x_k = F_k x_{k-1} + B_ku_k + w_k<br>$$</p><p>$$<br>z_k = H_k x_{k} + \epsilon_k<br>$$</p><ol start="2"><li>State noise $w_t$ and observation noise $\epsilon_t$ both follow normal distribution:</li></ol><p>$$<br>w_{k} \sim N(0, Q_k)<br>$$</p><p>$$<br>\epsilon_{k} \sim N(0, R_k)<br>$$</p><p>Also, we introduce $P_k = Var(x_k - \hat x_{k|k - 1})$ to describe the variance of estimate error (which is the difference between actual state $x_k$ and estimate state $\hat x_{k|k-1}$).</p><p><strong>Kalman Filter Derivation</strong></p><p>We follow the <strong>state prediction</strong> and <strong>state update</strong> procedure as above to derive $x_k$ and $P_k$</p><ol><li>State Prediction (Arrive at Apriori Estimate):</li></ol><p>$$<br>\hat x_{k|k-1} = F_{k} \hat x_{k-1|k-1} + B_k u_k + w_k<br>$$</p><p>$$<br>\begin {align<em>}<br>P_{k|k-1} &amp;= Var(x_{k} - \hat x_{k|k-1}) \<br>&amp;= Var(F_k(x_{k} - \hat x_{k|k-1}) + w_k) \<br>&amp;= F_k P_k F_k^T + Q_k<br>\end {align</em>}<br>$$</p><ol start="2"><li><p>State Update (Obtain the Posteriori Estimate):<br>$$<br>K_k = P_{k|k-1}H_k^T(H_k P_{k|k-1} H_k^T + R_k)^{-1}<br>$$</p><p>$$<br>\hat x_{k|k} = \hat x_{k|k-1} + K_k (z_k - H_k \hat x_{k|k-1})<br>$$</p><p>$$<br>P_{k|k} = [I - K H_k] P_{k|k-1}<br>$$</p><p>$K$ for <strong>Kalman Gain</strong> is how Kalman Filters extends from Bayesian Filter. Let’s first look at the state update which can be interpreted as <strong>apriori estimate</strong> plus a portion of <strong>predicted observation error</strong>.</p><p>Let’s then understand the structure of $K$, where<br>$$<br>Var(z_k - \hat z_{k|k-1}) = Var(H_k(x_k - \hat x_{k|k-1}) + \epsilon_k) = H_k P_{k|k-1} H_k^T + R_k<br>$$<br>So we can express the portion of predicted observation error as<br>$$<br>K_k (z_k - \hat z_{k|k-1}) = Var[x_k - x_{k|k-1}] H^T_k Var^{-1}[z_k - \hat z_{k|k-1}] (z_k - \hat z_{k|k-1})<br>$$<br>We can interpret $K$ as a compensation term for model prediction uncertainty.</p><p>A large $K$ means there is much more noise in state prediction (a relatively larger $P_{k|k-1}$) than in observation prediction (a relatively smaller $Var(z_k - \hat z_{k|k-1})$), then we apply a large correction term to apriori estimate $\hat x_{k|k-1}$ to approximate a more accurate posteriori $x_{k|k}$. Otherwise, a small $K$ means the current prediction $\hat x_{k|k-1}$ makes some sense so that a small correction is needed.</p><p>How is $K$ derived exactly? Follow the interpretation of $K$, we can think of $K$ must be the result of minimizing the state prediction error $P_{k|k}$. So let’s express $P_{k|k}$ as below<br>$$<br>\begin {align<em>}<br>P_{k|k} &amp;= Var(x_k - \hat x_{k|k}) = Var(x_k - [\hat x_{k|k-1} + K_k (z_k - H_k \hat x_{k|k-1})]) \<br>&amp;= Var(x_k - [\hat x_{k|k-1} + K_k (H_k x_{k} + \epsilon_k - H_k \hat x_{k|k-1})]) \<br>&amp;= Var(x_k - \hat x_{k|k-1} - K_k H_k(x_{k} - \hat x_{k|k-1}) - K_k\epsilon_k ) \<br>&amp;= Var((I - K_k H_k)(x_{k} - \hat x_{k|k-1})) + Var(K_k\epsilon_k ) \<br>&amp;= (I - K_k H_k)P_{k|k-1}(I - K_k H_k)^T + K_k R_k K_k^T\<br>\end {align</em>}<br>$$<br>Now we introduce $S_k = Var(z_k - \hat z_{k|k-1}) = H_k P_{k|k-1} H_k^T + R_k$, then we have<br>$$<br>P_{k|k} = P_{k|k-1} - K_k H_k P_{k|k-1} - P_{k|k-1}H_k^T K_k^T + K_k S_k K_k^T<br>$$<br>Now minimize the trace of $P_{k|k}$ to minimize the squared error, so we have<br>$$<br>\frac{\partial tr(P_{k|k})}{\partial K_k} = -2P_{k|k-1} H_k^T + 2K_k S_k = 0<br>$$<br>then we get $K_k = P_{k|k-1} H_k^T S_k^{-1}$</p></li></ol><p><strong>Kalman Filter Bayesian Derivation</strong></p><p>We stick to the recursion formula derived by Bayesian rules:<br>$$<br>Bel(x_k) = \eta p(z_k|x_k) \int p(x_k|x_{k-1},u_k) Bel(x_{k-1})dx_{k-1}<br>$$<br>Let’s give an initial condition $Bel(x_0) = N(x_0, P_0)$, then for $k=1$ with state dynamics $x_k = F_k x_{k-1} + B_k u_k + w_k$, we know $p(x_1|x_{0},u_1) = N(F_1 x_0 + B_1 u_1, Q_1)$.</p><p>According to <a href="https://users.aalto.fi/~ssarkka/course_k2016/handout3.pdf#page=14" target="_blank" rel="noopener">convolution rules</a> in Gaussian distribution, we can get<br>$$<br>\overline {Bel}(x_1) = N(F_1 x_0 + B_1 u_1, F_1 P_0 F_1^T + Q_1)<br>$$<br>The same goes for any other $k\geq 1$ as the recursion holds true for growing $k$, which is<br>$$<br>\overline {Bel}(x_k) = N(F_k x_{k-1} + B_k u_k, F_k P_{k-1} F_k^T + Q_k)<br>$$<br>For the observation-state mapping part, we know $p(z_k|x_k) = N(H_k x_k, R_t)$, so the problem now becomes computing the distribution of 2 Gaussian variables. This will definitely lead to the same results above like<br>$$<br>\eta N(H_k x_k, R_t) N(F_k x_{k-1} + B_k u_k, F_k P_{k-1} F_k^T + Q_k) \<br>= N(F_k x_{k-1} + B_k u_k + K_k (z_k - H_k (F_k x_{k-1} + B_k u_k)), [I - K H_k] P_{k|k-1})<br>$$<br>for now I have no idea how this can be derived rigorously, but <a href="http://www.tina-vision.net/docs/memos/2003-003.pdf" target="_blank" rel="noopener">P.A. Bromiley, Products and Convolutions of Gaussian Probability Density Functions</a> introduces deriving distribution of the product of n univariate Gaussian variables.</p><p><strong>Reference</strong>:</p><p>[1] <a href="https://www.cnblogs.com/ycwang16/p/5999034.html" target="_blank" rel="noopener">细说Kalman滤波：The Kalman Filter</a></p><p>[2] <a href="https://users.aalto.fi/~ssarkka/course_k2016/handout3.pdf" target="_blank" rel="noopener">Simo Särkkä, Bayesian Filtering Equations and Kalman Filter</a></p><p>[3] <a href="http://www.cs.cmu.edu/~16831-f14/notes/F14/16831_lecture02_prayana_tdecker_humphreh.pdf" target="_blank" rel="noopener">Statistical Techniques in Robotics (16-831, F10) Lecture #02 (Thursday, August 28)Bayes Filtering</a></p><p>[4] <a href="http://people.ciirc.cvut.cz/~hlavac/TeachPresEn/55AutonomRobotics/2015-05-04ReinsteinBayes-ekf.pdf" target="_blank" rel="noopener">Michal Reinštein, From Bayes to Extended Kalman Filter</a></p></div></div><nav class="post-pagination"><span class="page-number"></span> <a class="older-posts" href="/2019/10/20/CCA/">Next post<br>Canonical Component Analysis</a></nav></div></div><div class="single-column-footer">Proudly published with Hexo<br>Theme <a href="https://github.com/SumiMakito/hexo-theme-journal/" target="_blank" rel="noreferrer noopener">Journal.</a> by <a href="https://mak1t0.cc/" target="_blank" rel="noreferrer noopener">Makito</a><br>&copy; 2020 <a href="http://yoursite.com">Avalon</a></div></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.14.4/dist/umd/popper.min.js" integrity="sha256-EGs9T1xMHdvM1geM8jPpoo8EZ1V1VRsmcJz8OByENLA=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/vue@2.5.17/dist/vue.min.js" integrity="sha256-FtWfRI+thWlNz2sB3SJbwKx5PgMyKIVgwHCTwa3biXc=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/smooth-scroll@14.2.1/dist/smooth-scroll.polyfills.min.js" integrity="sha256-CI4Gq5E0io1Pv0xM3qPM+NUIOhbIBvC3GiN1Y4KhXpw=" crossorigin="anonymous"></script><script src="/js/journal.js?32660729"></script></body></html>
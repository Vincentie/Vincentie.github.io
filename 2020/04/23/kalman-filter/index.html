<!DOCTYPE html><html xmlns:v-bind="http://www.w3.org/1999/xhtml"><head><meta name="generator" content="Hexo 3.9.0"><title>A Mysterious Algorithm used in Apollo 11 Guidance - Avalon</title><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="John Reese"><meta name="description" content="Some Notes on State Space Models and Kalman Filtering"><meta name="keywords" content><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0" name="viewport"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><meta name="theme-color" content="#ffffff"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous"><link rel="stylesheet" href="/css/journal.css?10337991"><script src="/js/loadCSS.js"></script><script>loadCSS("https://fonts.googleapis.com/css?family=Lora|Montserrat|Fira+Mono|Material+Icons"),function(e){var t,a={kitId:"dwg1tuc",scriptTimeout:3e3,async:!0},o=e.documentElement,s=setTimeout(function(){o.className=o.className.replace(/\bwf-loading\b/g,"")+" wf-inactive"},a.scriptTimeout),c=e.createElement("script"),i=!1,n=e.getElementsByTagName("script")[0];o.className+=" wf-loading",c.src="https://use.typekit.net/"+a.kitId+".js",c.async=!0,c.onload=c.onreadystatechange=function(){if(t=this.readyState,!(i||t&&"complete"!=t&&"loaded"!=t)){i=!0,clearTimeout(s);try{Typekit.load(a)}catch(e){}}},n.parentNode.insertBefore(c,n)}(document)</script><noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora|Montserrat|Anonymous+Pro:400|Material+Icons"></noscript><link rel="stylesheet" href="/css/prism.css" type="text/css"></head><body><div id="top"></div><div id="app"><div class="single-column-drawer-container" ref="drawer" v-bind:class="{ 'single-column-drawer-container-active': isDrawerOpen }"><div class="drawer-content"><div class="drawer-menu"><a class="a-block drawer-menu-item false" href="http://yoursite.com">Home </a><a class="a-block drawer-menu-item false" href="/archives">記事一覽 </a><a class="a-block drawer-menu-item false" href="/about/index.html">關於我 </a><a class="a-block drawer-menu-item false" href="/categories/index.html">分類 </a><a class="a-block drawer-menu-item false" href="/tags/index.html">標簽</a></div></div></div><transition name="fade"><div v-bind:class="{ 'single-column-drawer-mask': mounted }" v-if="isDrawerOpen" v-on:click="toggleDrawer"></div></transition><nav ref="navBar" class="navbar sticky-top navbar-light single-column-nav-container"><div ref="navBackground" class="nav-background"></div><div class="container container-narrow nav-content"><button id="nav_dropdown_btn" class="nav-dropdown-toggle" type="button" v-on:click="toggleDrawer"><i class="material-icons">menu</i></button> <a ref="navTitle" class="navbar-brand" href="/">Avalon</a></div></nav><div class="single-column-header-container" ref="pageHead" v-bind:style="{ transform: 'translateZ(0px) translateY('+.3*scrollY+'px)', opacity: 1-navOpacity }"><a href="/"><div class="single-column-header-title">Avalon</div><div class="single-column-header-subtitle">Welcome!!</div></a></div><div ref="sideContainer" class="side-container"><a class="a-block nav-head false" href="/"><div class="nav-title">远い理想郷</div><div class="nav-subtitle">お帰りなさい</div></a><div class="nav-link-list"><a class="a-block no-tint nav-link-item false" href="/archives">記事一覽 </a><a class="a-block nav-link-item false" href="/about/index.html">關於我 </a><a class="a-block nav-link-item false" href="/categories/index.html">分類 </a><a class="a-block nav-link-item false" href="/tags/index.html">標簽</a></div><div class="nav-footer">Proudly published with Hexo<br>Theme <a href="https://github.com/SumiMakito/hexo-theme-journal/" target="_blank" rel="noreferrer noopener">Journal.</a> by <a href="https://mak1t0.cc/" target="_blank" rel="noreferrer noopener">Makito</a><br>&copy; 2020 <a href="http://yoursite.com">Avalon</a></div></div><div ref="extraContainer" class="extra-container"><div class="pagination"><a id="globalBackToTop" class="pagination-action animated-visibility" href="#top" :class="{ invisible: scrollY == 0 }"><i class="material-icons pagination-action-icon">keyboard_arrow_up</i></a></div></div><div ref="streamContainer" class="stream-container"><div class="post-list-container post-list-container-shadow"><div class="post"><div class="post-head-wrapper" style="background-image:url(/2020/04/23/kalman-filter/kf_cover.png)"><div class="post-title">A Mysterious Algorithm used in Apollo 11 Guidance<div class="post-meta"><time datetime="2020-04-24T01:05:54.000Z" itemprop="datePublished">2020-04-23 21:05 </time>&nbsp; <i class="material-icons">folder</i> <a href="/categories/Math/">Math</a> <i class="material-icons">label</i> <a href="/tags/Math/">Math</a>, <a href="/tags/Bayesian-Inference/">Bayesian Inference</a><script type="text/x-mathjax-config">MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            processEscapes: true
          }
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
          });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
              var all = MathJax.Hub.getAllJax(), i;
              for(i=0; i < all.length; i += 1) {
                  all[i].SourceElement().parentNode.className += ' has-jax';
              }
          });</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></div></div></div><div class="post-body-wrapper"><div class="post-body"><h2 id="kalman-filter">Kalman Filter</h2><h3 id="state-space-models">0. State Space Models</h3><p>In <a href="https://en.wikipedia.org/wiki/State-space_representation#Example:_continuous-time_LTI_case" target="_blank" rel="noopener">Wikipedia</a>, a state space model is described as a set of input, output and state variables mixed with some ODE systems. I have no idea what that is with this abstract definition. State variables</p><p>can also be known as hidden states evolving through time in a way that we don't know how but we would like to use some <strong>dynamics</strong> and <strong>observations</strong> to fit the evolution path.</p><p><strong>An Example</strong></p><p>Let's look at a random walk example below,</p><p>Say we model some hidden states with two parts, which are its last state and some random noise. Also, we give the mapping relationship from <span class="math inline">\(x_t\)</span> to <span class="math inline">\(z_t\)</span> as below. <span class="math display">\[ x_t = x_{t - 1} + w_{t - 1}, w_{t} \sim N(0, Q), \\ z_t = x_t + \epsilon_{t}, \epsilon_{t} \sim N(0, R) \]</span></p><p>where <span class="math inline">\(x_t\)</span> is the state variable and <span class="math inline">\(z_t\)</span> is the observation value, and <span class="math inline">\(w_t\)</span>, <span class="math inline">\(\epsilon_{t}\)</span> are independent normal random noise.</p><p><img src="kalman-filter//random_walk.png" align="center/"></p><figure><img src="random_walk.png" alt="Random walk"><figcaption>Random walk</figcaption></figure><p>Basically, we have a state space model about <span class="math inline">\(x_t\)</span>, and we would like to know how exactly <span class="math inline">\(x_t\)</span> will evolve in future steps. From the equations above, we can also estimate <span class="math inline">\(\hat x_t\)</span> with current <span class="math inline">\(\hat x_{t - 1}\)</span> and <span class="math inline">\(z_{t-1}\)</span>.</p><p><strong>Probabilistic State Space Models</strong></p><p>But usually, a point estimate is less significant than an interval estimate. So here comes Probabilistic State Space Models.</p><p>With the same example above, we can know the distribution of <span class="math inline">\(x_t\)</span> given <span class="math inline">\(x_{t-1}\)</span>and the distribution of observations <span class="math inline">\(z_t\)</span> given <span class="math inline">\(x_{t}\)</span>. <span class="math display">\[ p(x_t | x_{t - 1}) = \frac{1}{\sqrt{2 \pi Q}}\exp \left( -\frac{1}{2Q}(x_t - x_{t - 1})^2 \right) \\ p(z_t | x_t) = \frac{1}{\sqrt{2 \pi R}}\exp \left( -\frac{1}{2R}(z_t - x_t)^2 \right) \]</span></p><p>where <span class="math inline">\(p(\cdot)\)</span> represents a probability density function.</p><p><strong>Assumptions</strong></p><p>Typically, we use <span class="math inline">\(p(x_t | x_{t - 1})\)</span> instead of <span class="math inline">\(p(x_t | x_{1},x_{2},...,x_{t - 1})\)</span> to describe the conditional distribution is due to the Markovian assumption, which is <strong>future states are independent from the past states given the present.</strong> <span class="math display">\[ p(x_t | x_{t - 1}) = p(x_t | x_{1},x_{2},...,x_{t - 1}, z_{1},z_{2},...,z_{t - 1}) \]</span> Also, we can also naturally think of the relationship between states and observations. Obviously, <strong>observations only depend on its current states</strong> instead of past observations or past states. <span class="math display">\[ p(z_t | x_t) = p(z_t | x_{1},x_{2},...,x_{t}, z_{1},z_{2},...,z_{t - 1}) \]</span> Simpler forms of these assumptions are as below <span class="math display">\[ p(x_t | x_{1:t-1}, z_{1:t}) = p(x_t | x_{t - 1}) \\ p(z_t | x_{1:t}, z_{1:t - 1}) = p(z_t | x_t) \]</span></p><h3 id="bayesian-filter">1. Bayesian Filter</h3><p>Before we talk about Bayesian Filter, let's focus on what filtering is. Filtering is actually one of the statistical inference methods</p><ul><li><strong><em>Filtering</em></strong>. Filtering means to recover the state variable <span class="math inline">\(x_t\)</span> given <span class="math inline">\(z_{1:t}\)</span>, that is, to remove the measurement errors from the data.</li><li><strong><em>Prediction</em></strong>. Prediction means to forecast <span class="math inline">\(x_{t+h}\)</span> or <span class="math inline">\(z_{t+h}\)</span> for <span class="math inline">\(h&gt;0\)</span> given <span class="math inline">\(z_{1:t}\)</span>, where <span class="math inline">\(t\)</span> is the forecast origin.</li><li><strong><em>Smoothing</em></strong>. Smoothing is to estimate <span class="math inline">\(x_t\)</span> given <span class="math inline">\(z_{1:T}\)</span>, where <span class="math inline">\(T&gt;t\)</span>.</li></ul><p>From <a href="https://en.wikipedia.org/wiki/Bayesian_inference" target="_blank" rel="noopener">Bayesian inference</a>, the probability for an event is updated as more evidence or information becomes available, so we would like to use Bayes rules to <strong>simulate</strong> the probability distribution of hidden states <span class="math inline">\(x_t\)</span> with incoming observations. <span class="math display">\[ \begin{align*} p(x_t |z_{1:t}) &amp;= \frac{p(x_t, z_{1:t})}{p( z_{1:t})}\\ &amp;= \frac{p(z_t | z_{1:t-1}, x_t) p(x_t |z_{1:t-1}) p(z_{1:t-1})}{p(z_{1:t})}, \space where \space p(z_t | z_{1:t-1}, x_t) = p(z_t | x_t) \\ &amp;= \eta p(z_t | x_t) p(x_t | z_{1:t-1}), \space where \space\space \eta = p(z_t | z_{1:t-1})\\ &amp;= \eta p(z_t | x_t) \int{p(x_t | x_{t-1}, z_{1:t-1})p(x_{t-1} | z_{1:t-1})dx_{t-1}}\\ &amp;= \eta p(z_t | x_t) \int{p(x_t | x_{t-1})p(x_{t-1} | z_{1:t-1})dx_{t-1}}\\ \end{align*} \]</span> Here comes a recursion formula if we replace <span class="math inline">\(p(x_t |u_{1:t})\)</span> with <span class="math inline">\(Bel(x_t)\)</span> meaning the posterior pdf of <span class="math inline">\(x_t\)</span> at time <span class="math inline">\(k\)</span>, so we have <span class="math display">\[ Bel(x_t) = \eta p(z_t|x_t) \int p(x_t|x_{t-1})Bel(x_{t-1})dx_{t-1} \]</span> where <span class="math inline">\(p(z_t|x_t)\)</span> and <span class="math inline">\(p(x_t|x_{t-1})\)</span> correspond exactly to the 2 hypothetical equations discussed in the random walk example, which are <strong>Observations-States Mapping</strong> and <strong>State Dynamics</strong>. Intuitively, we need state dynamics to make apriori estimates (<span class="math inline">\(\int{p(x_t | x_{t-1})p(x_{t-1} | z_{1:t-1})dx_{t-1}}\)</span>) and observations to make likelihood adjustments, thus making the Bayesian rules complete. The slides of <a href="https://users.aalto.fi/~ssarkka/course_k2016/handout3.pdf#page=12" target="_blank" rel="noopener">Bayesian Filtering Equations andKalman Filter from Simo Särkkä in Aalto University</a> shows how the distribution of <span class="math inline">\(x_{t}\)</span> evolves under Bayesian rules.</p><p><strong>A New Input</strong></p><p>Now we introduce another control variable <span class="math inline">\({u_t}\)</span> which may serve as an additional impact to <span class="math inline">\(x_t\)</span>, and we can now imagine the state model has the new form like below: <span class="math display">\[ x_t = x_{t - 1} + u_t + w_{t - 1}, w_t \sim N(0, Q), \\ z_t = x_t + \epsilon_t, \epsilon_t \sim N(0, R) \]</span></p><p>Also, we cast those 2 assumptions to <span class="math inline">\(u_t\)</span>, then we have <span class="math display">\[ p(x_t | x_{1:t-1}, u_{1:t}, z_{1:t}) = p(x_t | x_{t - 1}, u_t) \\ p(z_t | x_{1:t}, u_{1:t}, z_{1:t - 1}) = p(z_t | x_t) \]</span></p><p>The target conditional probability distribution has now become posterior distribution <span class="math inline">\(p(x_t | u_{1:t}, z_{1:t})\)</span>, we would like to know how the current state behaves given the most recent series of observations and control variables. <span class="math display">\[ \begin{align*} p(x_t |u_{1:t}, z_{1:t}) &amp;= \frac{p(x_t, u_{1:t}, z_{1:t})}{p(u_{1:t}, z_{1:t})}\\ &amp;= \frac{p(z_t | u_{1:t}, z_{1:t-1}, x_t) p(x_t | u_{1:t}, z_{1:t-1}) p(u_{1:t}, z_{1:t-1})}{p(u_{1:t}, z_{1:t})}\\ &amp;= \eta p(z_t | x_t) p(x_t | u_{1:t}, z_{1:t-1}), \space where \space\space \eta = p(z_t | u_{1:t}, z_{1:t-1})\\ &amp;= \eta p(z_t | x_t) \int{p(x_t | x_{t-1}, u_{1:t}, z_{1:t-1})p(x_{t-1} | u_{1:t}, z_{1:t-1})dx_{t-1}}\\ &amp;= \eta p(z_t | x_t) \int{p(x_t | x_{t-1}, u_t)p(x_{t-1} | u_{1:t-1}, z_{1:t-1})dx_{t-1}}\\ \end{align*} \]</span> Here comes a recursion formula if we replace <span class="math inline">\(p(x_t |u_{1:t}, z_{1:t})\)</span> with <span class="math inline">\(Bel(x_t)\)</span> meaning the posterior pdf of <span class="math inline">\(x_t\)</span> at time <span class="math inline">\(t\)</span>, so we have <span class="math display">\[ Bel(x_t) = \eta p(z_t|x_t) \int p(x_t|x_{t-1}, u_t) Bel(x_{t-1})dx_{t-1} \]</span> which is all the same as the previous formula except <span class="math inline">\(u_t\)</span>. Now we can separate this recursion formula into two parts <span class="math display">\[ \overline {Bel}{(x_t)} = \int p(x_t|x_{t-1}, u_t) Bel(x_{t-1})dx_{t-1} \\ Bel(x_t) = \eta p(z_t|x_t)\overline {Bel}{(x_t)} \]</span></p><p>state prediction and state update respectively. We can say <span class="math inline">\(x_t\)</span> is predicted with new inputs of control variables <span class="math inline">\(u_t\)</span> and updated with corresponding observations <span class="math inline">\(z_t\)</span>.</p><p>Why we need a new input <span class="math inline">\(u_t\)</span>? Simply speaking, we need some other factors rather than pure past states to explain the evolution of <span class="math inline">\(x_t\)</span>. To be more specific, Bayesian filter is widely used in probabilistic robotics where there is always robotics control (say robots are controlled to move 2 meters ahead) and the control itself influences a system's state (the state is the position of the robot).</p><h3 id="kalman-filter-1">2. Kalman Filter</h3><p>The recursion equation above indicates how the distribution of <span class="math inline">\(x_t\)</span> evolves through time. However we do not know what is the exact distribution of <span class="math inline">\(x_{t-1}\)</span> given a random initial distribution <span class="math inline">\(x_0\)</span>. If an initial random distribution is given, then we must follow the recursion formula to integrate over all possible <span class="math inline">\(x_{t-1}\)</span> to get an estimate.</p><p>Here comes the trick of Kalman Filter-using <strong>Gaussian</strong> distributions to describe <span class="math inline">\(x_t\)</span>. Because linear combinations of Gaussian distributions are still Gaussian, the states distribution evolution is easier to follow under Gaussian assumptions.</p><p><strong>Notations and Assumptions</strong> <span class="math display">\[ x_{t+1} = A_{t} x_{t} + w_t \\ z_t = H_t x_{t} + \epsilon_t \]</span></p><ul><li><span class="math inline">\(A_t\)</span> is the state transition matrix.</li><li><p><span class="math inline">\(H_t\)</span> is the observation-state mapping matrix.</p></li><li><span class="math inline">\(F_t = \{z_1, . . . , z_t \}\)</span> is the information available at time <span class="math inline">\(t\)</span> (inclusive).</li><li><span class="math inline">\(x_{t|j} = E(x_t|F_j)\)</span> is the conditional mean of <span class="math inline">\(x_t\)</span> given <span class="math inline">\(F_j\)</span>.</li><li><span class="math inline">\(z_{t|j} = E(z_t|F_j)\)</span> is the conditional mean of <span class="math inline">\(z_t\)</span> given <span class="math inline">\(F_j\)</span>.</li><li><span class="math inline">\(\Sigma_{t|j} = Var(x_t|F_j)\)</span> is the conditional variance of <span class="math inline">\(x_t\)</span> given <span class="math inline">\(F_j\)</span> and also the <span class="math inline">\(t-j\)</span> step state estimation error at the same time.</li><li><span class="math inline">\(v_t= z_t - z_{t|t-1}\)</span> is the 1-step-ahead forecast error.</li><li><span class="math inline">\(V_t= Var(v_t|F_{t-1})\)</span> is the variance of the 1-step-ahead forecast error, which is at the same time the unconditional variance <span class="math inline">\(Var(v_t)\)</span>.</li><li><p><span class="math inline">\(Cov(v_t, z_j) = E[E(v_t z_j|F_{t-1})] = E[z_j E(v_t |F_{t-1})] = 0, \space \space j &lt; t\)</span> indicates the 1-step-ahead forecast error is uncorrelated (and hence independent) with the past observations <span class="math inline">\(z_j\)</span>.</p></li></ul><p>It's easy to derive that <span class="math display">\[ E(v_t) = E[E(v_t|F_{t-1})] = E[E(z_t - z_{t|t-1}|F_{t-1})] = E(z_{t|t-1} - z_{t|t-1}) = 0 \\ \begin{align} V_t &amp;= Var(z_t - z_{t|t-1}|F_{t-1}) \\ &amp;= Var(H_t x_t + \epsilon_t - H_t x_{t|t-1} |F_{t-1}) \\ &amp;= H_t \Sigma_{t|t-1} H_t^T + \sigma^2_{\epsilon} \end{align} \]</span> which is to say <span class="math display">\[ v_t|F_{t-1} \sim N(0, V_t) \]</span> with <span class="math inline">\(x_t|F_{t-1} \sim N(x_{t|t-1}, \Sigma_{t|t-1})\)</span>, we know the joint distribution of <span class="math inline">\(x_t\)</span> and <span class="math inline">\(v_t\)</span> given <span class="math inline">\(F_{t-1}\)</span> is a multi-variate normal distribution. The remaining question is what is the conditional covariance between <span class="math inline">\(x_t\)</span> and <span class="math inline">\(z_t\)</span> given <span class="math inline">\(F_{t-1}\)</span>. <span class="math display">\[ \begin{align} Cov(x_t, v_t | F_{t-1}) &amp;= Cov(x_t, H_tx_t + \epsilon_t - H_t x_{t|t-1}| F_{t-1}) \\ &amp;= Cov(x_t, H_t(x_t - x_{t|t-1})| F_{t-1}) + Cov(x_t, \epsilon_t | F_{t-1}) \\ &amp;= Cov(x_t - x_{t|t-1}, H_t(x_t - x_{t|t-1})| F_{t-1}) \\ &amp;= \Sigma_{t|t-1} H_t^T \end{align} \]</span> So the joint distribution is $$ \begin{bmatrix} x_t \ v_t \end{bmatrix}<em>{F</em>{t-1}}</p><p></p><p>N(\begin{bmatrix} x_{t|t-1} \ 0 \end{bmatrix}, \begin{bmatrix} <em>{t|t-1} &amp; H_t </em>{t|t-1} \ <em>{t|t-1} H_t^T &amp; V_t \end{bmatrix}) <span class="math display">\[ And the goal of the Kalman filter is to update knowledge of the state variable recursively when new data become available. In other words, knowing the conditional distribution of $x_t$ given $F_{t−1}$ and the new observation $z_t$, we would like to obtain the conditional distribution of $x_t$ given $F_t$. Before that, let&#39;s first introduce some theorems about conditional mean and variance. Suppose that $x$, $y$, and $z$ are three random vectors such that their joint distribution is multivariate normal. In addition, assume that the diagonal block covariance matrix $\Sigma_{ww}$ is nonsingular for $w = x, y, z$, and $\Sigma_{yz} = 0$. Then, \]</span> 1. E(x|y) = <em>x + </em>{xy} </em>{yy}^{-1} (y - <em>y)\ 2. Var(x|y) = </em>{xx} - <em>{xx} </em>{yy}^{-1} <em>{yx} \ 3. E(x|y, z) = E(x|y) + </em>{xz} <em>{zz}^{-1} (z - <em>z) \ 4. Var(x|y, z) = Var(x|y) - </em>{xz} </em>{zz}^{-1} <em>{zx} <span class="math display">\[ And therefore we can get \]</span> x</em>{t|t} = E(x_t|F_{t-1}, v_t) = x_{t|t-1} + <em>{t|t-1} H_t^T V_t^{-1}v_t \ </em>{t|t} = Var(x_t|F_{t-1}, v_t) = <em>{t|t-1} - </em>{t|t-1} H_t^T V_t^{-1} H_t <em>{t|t-1} <span class="math display">\[ If we define $K_t = \Sigma_{t|t-1} H_t^T V_t^{-1}$, then we have \]</span> x</em>{t|t} = x_{t|t-1} + K_t v_t \ <em>{t|t} = (I - K_t H_t) </em>{t|t-1} $$</p><p>These are 2 filtering equations. Besides that, Kalman Filter also gives prediction based on the filtered results as below. <span class="math display">\[ x_{t+1|t} = E(A_t x_t + w_t|F_t) = A_t x_{t|t} \\ \Sigma_{t+1|t} = Var(x_t + w_t |F_t) = Var(x_t|F_t) + Var(w_t|F_t) = \Sigma_{t|t} + \sigma^2_{\epsilon} \]</span> With the initial condition <span class="math inline">\(\mu_1 \sim N(\mu_{1|0}, \Sigma_{1|0})\)</span>, the Kalman Filtering is ready for the above dynamics.</p><p><strong>Another way of deriving K from an optimization perspective</strong></p><p><span class="math inline">\(K_t\)</span> for <strong>Kalman Gain</strong> is how Kalman Filters extends from Bayesian Filter. The state filtering can be decomposed of <strong>apriori estimate</strong> plus a portion of <strong>forecast error</strong> which is</p><p><span class="math display">\[ Var(z_t - z_{t|t - 1}) = Var(H_t (x_t - x_{t|t-1}) + \epsilon_k) = H_t P_{t|t-1} H_t^T + \sigma^2_{\epsilon} \]</span> So we can express the portion of predicted observation error as <span class="math display">\[ K_t (z_t - z_{t|t-1}) = Var[x_t - x_{t|t-1}] H^T_t Var^{-1}[z_t - z_{t|t-1}] (z_t - z_{t|t-1}) \]</span> We can interpret <span class="math inline">\(K_t\)</span> as a compensation term for model forecast uncertainty.</p><p>A large <span class="math inline">\(K_t\)</span> means there is much more noise in state forecast (a relatively larger <span class="math inline">\(\Sigma_{t|t-1}\)</span>) than in observation forecast (a relatively smaller <span class="math inline">\(Var(z_t - z_{t|t-1})\)</span>), then we apply a large correction term to apriori estimate <span class="math inline">\(x_{t|t-1}\)</span> to approximate a more accurate posteriori <span class="math inline">\(x_{t|t}\)</span>. Otherwise, a small <span class="math inline">\(K_t\)</span> means the current forecast <span class="math inline">\(x_{t|t-1}\)</span> makes some sense so that a small correction is fine.</p><p>How is <span class="math inline">\(K_t\)</span> derived exactly? Follow the interpretation of <span class="math inline">\(K_t\)</span>, we can think of <span class="math inline">\(K_t\)</span> must be the result of minimizing the state estimation error <span class="math inline">\(\Sigma_{t|t}\)</span>. So let's express <span class="math inline">\(\Sigma_{t|t}\)</span> as below <span class="math display">\[ \begin {align*} \Sigma_{t|t} &amp;= Var(x_t - x_{t|t}) = Var(x_t - [x_{t|t-1} + K_t (z_t - z_{t|t-1})]) \\ &amp;= Var(x_t - [x_{t|t-1} + K_t (H_t x_t + \epsilon_t - H_t x_{t|t-1})]) \\ &amp;= Var(x_t - x_{t|t-1} - K_t H_t(x_t - x_{t|t-1}) - K_t \epsilon_t) \\ &amp;= Var((I - K_t H_t)(x_t - x_{k|k-1})) + Var(K_t \epsilon_t) \\ &amp;= (I - K_t H_t)\Sigma_{t|t-1}(I - K_t H_t)^T + K_t \sigma^2_{\epsilon} K_t^T\\ \end {align*} \]</span> Since <span class="math inline">\(V_t = Var(z_t - z_{t|t-1}) = H_t \Sigma_{t|t-1} H_t^T + \sigma^2_{\epsilon}\)</span>, then we have <span class="math display">\[ \Sigma_{t|t} = \Sigma_{t|t-1} - K_t H_t \Sigma_{t|t-1} - \Sigma_{t|t-1} H_t^T K_t^T + K_t V_t K_t^T \]</span> Now minimize the trace of <span class="math inline">\(P_{t|t}\)</span> to minimize the squared error, so we have <span class="math display">\[ \frac{\partial tr(P_{t|t})}{\partial K_t} = -2P_{t|t-1} H_t^T + 2K_t V_t = 0 \]</span> then we get <span class="math inline">\(K_t = P_{t|t-1} H_t^T V_t^{-1}\)</span></p><p><strong>Kalman Filter Derivation from an Intuitive Bayesian Perspective</strong></p><p>We stick to the recursion formula derived by Bayesian rules: <span class="math display">\[ Bel(x_t) = \eta p(z_t|x_t) \int p(x_t|x_{t-1},u_t) Bel(x_{t-1})dx_{t-1} \]</span> Let's give an initial condition <span class="math inline">\(Bel(x_0) = N(x_0, P_0)\)</span>, then for <span class="math inline">\(k=1\)</span> with state dynamics <span class="math inline">\(x_{t+1} = A_t x_{t} + B_{t+1} u_{t+1} + w_t\)</span>, we know <span class="math inline">\(p(x_1|x_{0},u_1) = N(A_0 x_0 + B_1 u_1, \sigma_{w,0}^2)\)</span>.</p><p>According to <a href="https://users.aalto.fi/~ssarkka/course_k2016/handout3.pdf#page=14" target="_blank" rel="noopener">convolution rules</a> in Gaussian distribution, we can get <span class="math display">\[ \overline {Bel}(x_1) = N(A_0 x_0 + B_1 u_1, A_0 \Sigma_{1|0} A_0^T + \sigma_{w,0}^2) \]</span> The same goes for any other <span class="math inline">\(t \geq 1\)</span> as the recursion holds true for growing <span class="math inline">\(t\)</span>, which is <span class="math display">\[ \overline {Bel}(x_t) = N(A_{t-1} x_{t-1} + B_t u_t, A_{t-1} \Sigma_{t|t-1} A_{t-1}^T + \sigma_{w,t-1}^2) \]</span> For the observation-state mapping part, we know <span class="math inline">\(p(z_t|x_t) = N(H_t x_t, \sigma_{\epsilon, t}^2)\)</span>, so the problem now becomes computing the distribution of the product of 2 Gaussian variables. This will definitely lead to the same results above like <span class="math display">\[ \eta N(H_t x_t, \sigma_{\epsilon,t}^2) N(A_{t-1} x_{t-1} + B_t u_t, A_{t-1} \Sigma_{t|t-1} A_{t-1}^T + \sigma_{w,t-1}^2) \\ = N(A_{t-1} x_{t-1} + B_t u_t + K_t v_t, (I - K_t H_t) \Sigma_{t|t-1}) \]</span> for now I have no idea how this can be derived rigorously, but <a href="https://pdfs.semanticscholar.org/6414/4a7b0b8dd5389463a6886b9dc3304203a7e4.pdf" target="_blank" rel="noopener">P.A. Bromiley, Products and Convolutions of Gaussian Probability Density Functions</a> introduces deriving distribution of the product of <span class="math inline">\(n\)</span> univariate Gaussian variables.</p><h3 id="applications">3. Applications</h3><p>Intuitively, I would say <em>Bayesian</em> formula establishes the relationship among posterior distributions, likelihood functions and priori distributions and therefore gives the posterior distribution estimate in a recursive way. This process of stepwise estimating and making corrections is how probability is interpreted and inferred over time in a <em>Bayesian</em> way. Based on this, <strong>Kalman Filter</strong> makes assumptions about the 1. dynamics of states and observations to adapt to the <em>Bayesian</em> framework and therefore get 2. the way of estimating states and prediction error matrices. At the same time, <strong>Kalman Filter</strong> seeks to estimate the states' posterior distributions in a way that the states' prediction errors are minimized. In short, this can be seen as using normal distributions assumptions on Bayesian Filters to get the best estimates of states. Let's talk about some examples</p><p><strong>Temperature Measurement</strong></p><p>We use simple dynamics to model the average temperature in a certain region in a period of time <span class="math display">\[ x_t = x_{t-1} + w_t, \space \space \space w_t \sim N(0, \sigma_e^2) \\ z_t = x_{t} + \epsilon_t, \space \space \space \epsilon_t \sim N(0, \sigma_{\epsilon}^2) \]</span></p><p>The initial value <span class="math inline">\(x_1\)</span> is either given or follows a known distribution, and it is independent of <span class="math inline">\(\{w_t\}\)</span> and <span class="math inline">\(\{\epsilon_t\}\)</span> for <span class="math inline">\(t &gt;0\)</span>.</p><p>It has another name which is the <strong>Local Trend Model</strong>. In the model, <span class="math inline">\(x_t\)</span> is simply a random walk. <span class="math inline">\(x_t\)</span> can be referred to as the trend of the temperature which is not directly observable, and <span class="math inline">\(z_t\)</span> is the temperature detected by some sensors with observational noise <span class="math inline">\(\epsilon_t\)</span>. The dynamic dependence of <span class="math inline">\(z_t\)</span> is governed by <span class="math inline">\(x_t\)</span>'s dynamics because <span class="math inline">\(\epsilon_t\)</span> is not serially correlated.</p><blockquote><p>The model can also be used to analyze realized volatility of an asset price. Here <span class="math inline">\(x_t\)</span> represents the underlying log volatility of the asset price and <span class="math inline">\(x_t\)</span> is the logarithm of realized volatility. The true log volatility is not directly observed but evolves over time according to a random-walk model. On the other hand, <span class="math inline">\(x_t\)</span> is constructed from high-frequency transactions data and subjected to the influence of market microstructure noises. The standard deviation of <span class="math inline">\(\epsilon_t\)</span> denotes the scale used to measure the impact of market microstructure noises.</p></blockquote><p><strong>Pair Trading</strong></p><p>We use simple dynamics to model the dynamic relationship among different securities over time <span class="math display">\[ \beta_t = \beta_{t-1} + \epsilon_t \\ p^A_t = \beta_t p^B_t + w_t \]</span></p><p>where $p^A_t $ and <span class="math inline">\(p^B_t\)</span> are the price series of the pair, <span class="math inline">\(\beta_t\)</span> is the time-varying hedge ratio, <span class="math inline">\(w_t\)</span> and <span class="math inline">\(\epsilon_t\)</span> are independent normal error terms.</p><blockquote><p>The second equation represents the observation equation and the first equation is the state transition equation. This model suggests that the hidden state, which is the hedge ratio, follows a random walk. In order to make an estimation of the hidden state with Kalman filter, the observation error terms and transition error terms need to be estimated and specified.</p></blockquote><p><strong>Macroeconomic Nowcasting</strong></p><p>There is a <a href="https://towardsdatascience.com/macroeconomic-nowcasting-with-kalman-filtering-557926dbc737" target="_blank" rel="noopener">blog</a> demonstrating how Kalman filter helps in macroeconomic indicators nowcasting.</p><p><strong>Reference</strong>:</p><ol type="1"><li><a href="https://www.cnblogs.com/ycwang16/p/5999034.html" target="_blank" rel="noopener">细说Kalman滤波：The Kalman Filter</a></li><li><a href="https://users.aalto.fi/~ssarkka/course_k2016/handout3.pdf" target="_blank" rel="noopener">Simo Särkkä, Bayesian Filtering Equations and Kalman Filter</a></li><li><a href="http://www.cs.cmu.edu/~16831-f14/notes/F14/16831_lecture02_prayana_tdecker_humphreh.pdf" target="_blank" rel="noopener">Statistical Techniques in Robotics (16-831, F10) Lecture #02 (Thursday, August 28)Bayes Filtering</a></li><li><a href="http://people.ciirc.cvut.cz/~hlavac/TeachPresEn/55AutonomRobotics/2015-05-04ReinsteinBayes-ekf.pdf" target="_blank" rel="noopener">Michal Reinštein, From Bayes to Extended Kalman Filter</a></li><li><a href="https://uwspace.uwaterloo.ca/handle/10012/12793" target="_blank" rel="noopener">High Frequency Statistical Arbitrage with Kalman Filter and Markov Chain Monte Carlo</a></li></ol></div></div><nav class="post-pagination"><a class="newer-posts" href="/2020/05/02/SVD/">Previous post<br>Singular Value Decomposition </a><span class="page-number"></span> <a class="older-posts" href="/2019/10/20/CCA/">Next post<br>Canonical Component Analysis</a></nav></div></div><div class="single-column-footer">Proudly published with Hexo<br>Theme <a href="https://github.com/SumiMakito/hexo-theme-journal/" target="_blank" rel="noreferrer noopener">Journal.</a> by <a href="https://mak1t0.cc/" target="_blank" rel="noreferrer noopener">Makito</a><br>&copy; 2020 <a href="http://yoursite.com">Avalon</a></div></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.14.4/dist/umd/popper.min.js" integrity="sha256-EGs9T1xMHdvM1geM8jPpoo8EZ1V1VRsmcJz8OByENLA=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/vue@2.5.17/dist/vue.min.js" integrity="sha256-FtWfRI+thWlNz2sB3SJbwKx5PgMyKIVgwHCTwa3biXc=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/smooth-scroll@14.2.1/dist/smooth-scroll.polyfills.min.js" integrity="sha256-CI4Gq5E0io1Pv0xM3qPM+NUIOhbIBvC3GiN1Y4KhXpw=" crossorigin="anonymous"></script><script src="/js/journal.js?40370220"></script></body></html>
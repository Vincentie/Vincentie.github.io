<!DOCTYPE html><html xmlns:v-bind="http://www.w3.org/1999/xhtml"><head><meta name="generator" content="Hexo 3.9.0"><title>A Mysterious Algorithm used in Apollo 11 Guidance - Avalon</title><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="John Reese"><meta name="description" content="Some Notes on State Space Models and Kalman Filtering"><meta name="keywords" content><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0" name="viewport"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><meta name="theme-color" content="#ffffff"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous"><link rel="stylesheet" href="/css/journal.css?9610132"><script src="/js/loadCSS.js"></script><script>loadCSS("https://fonts.googleapis.com/css?family=Lora|Montserrat|Fira+Mono|Material+Icons"),function(e){var t,a={kitId:"dwg1tuc",scriptTimeout:3e3,async:!0},o=e.documentElement,s=setTimeout(function(){o.className=o.className.replace(/\bwf-loading\b/g,"")+" wf-inactive"},a.scriptTimeout),c=e.createElement("script"),i=!1,n=e.getElementsByTagName("script")[0];o.className+=" wf-loading",c.src="https://use.typekit.net/"+a.kitId+".js",c.async=!0,c.onload=c.onreadystatechange=function(){if(t=this.readyState,!(i||t&&"complete"!=t&&"loaded"!=t)){i=!0,clearTimeout(s);try{Typekit.load(a)}catch(e){}}},n.parentNode.insertBefore(c,n)}(document)</script><noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora|Montserrat|Anonymous+Pro:400|Material+Icons"></noscript><link rel="stylesheet" href="/css/prism.css" type="text/css"></head><body><div id="top"></div><div id="app"><div class="single-column-drawer-container" ref="drawer" v-bind:class="{ 'single-column-drawer-container-active': isDrawerOpen }"><div class="drawer-content"><div class="drawer-menu"><a class="a-block drawer-menu-item false" href="http://yoursite.com">Home </a><a class="a-block drawer-menu-item false" href="/archives">記事一覽 </a><a class="a-block drawer-menu-item false" href="/about/index.html">關於我 </a><a class="a-block drawer-menu-item false" href="/categories/index.html">分類 </a><a class="a-block drawer-menu-item false" href="/tags/index.html">標簽</a></div></div></div><transition name="fade"><div v-bind:class="{ 'single-column-drawer-mask': mounted }" v-if="isDrawerOpen" v-on:click="toggleDrawer"></div></transition><nav ref="navBar" class="navbar sticky-top navbar-light single-column-nav-container"><div ref="navBackground" class="nav-background"></div><div class="container container-narrow nav-content"><button id="nav_dropdown_btn" class="nav-dropdown-toggle" type="button" v-on:click="toggleDrawer"><i class="material-icons">menu</i></button> <a ref="navTitle" class="navbar-brand" href="/">Avalon</a></div></nav><div class="single-column-header-container" ref="pageHead" v-bind:style="{ transform: 'translateZ(0px) translateY('+.3*scrollY+'px)', opacity: 1-navOpacity }"><a href="/"><div class="single-column-header-title">Avalon</div><div class="single-column-header-subtitle">Welcome!!</div></a></div><div ref="sideContainer" class="side-container"><a class="a-block nav-head false" href="/"><div class="nav-title">远い理想郷</div><div class="nav-subtitle">お帰りなさい</div></a><div class="nav-link-list"><a class="a-block no-tint nav-link-item false" href="/archives">記事一覽 </a><a class="a-block nav-link-item false" href="/about/index.html">關於我 </a><a class="a-block nav-link-item false" href="/categories/index.html">分類 </a><a class="a-block nav-link-item false" href="/tags/index.html">標簽</a></div><div class="nav-footer">Proudly published with Hexo<br>Theme <a href="https://github.com/SumiMakito/hexo-theme-journal/" target="_blank" rel="noreferrer noopener">Journal.</a> by <a href="https://mak1t0.cc/" target="_blank" rel="noreferrer noopener">Makito</a><br>&copy; 2020 <a href="http://yoursite.com">Avalon</a></div></div><div ref="extraContainer" class="extra-container"><div class="pagination"><a id="globalBackToTop" class="pagination-action animated-visibility" href="#top" :class="{ invisible: scrollY == 0 }"><i class="material-icons pagination-action-icon">keyboard_arrow_up</i></a></div></div><div ref="streamContainer" class="stream-container"><div class="post-list-container post-list-container-shadow"><div class="post"><div class="post-head-wrapper" style="background-image:url(/2020/04/23/kalman-filter/kf_cover.png)"><div class="post-title">A Mysterious Algorithm used in Apollo 11 Guidance<div class="post-meta"><time datetime="2020-04-24T01:05:54.000Z" itemprop="datePublished">2020-04-23 21:05 </time>&nbsp; <i class="material-icons">folder</i> <a href="/categories/Quant/">Quant</a><script type="text/x-mathjax-config">MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            processEscapes: true
          }
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
          });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
              var all = MathJax.Hub.getAllJax(), i;
              for(i=0; i < all.length; i += 1) {
                  all[i].SourceElement().parentNode.className += ' has-jax';
              }
          });</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></div></div></div><div class="post-body-wrapper"><div class="post-body"><h2 id="kalman-filter">Kalman Filter</h2><h3 id="state-space-models">0. State Space Models</h3><p>In <a href="https://en.wikipedia.org/wiki/State-space_representation#Example:_continuous-time_LTI_case" target="_blank" rel="noopener">Wikipedia</a>, a state space model is described as a set of input, output and state variables mixed with some ODE systems. I have no idea what that is with this abstract definition. State variables</p><p>can also be known as hidden states evolving through time in a way that we don't know how but we would like to use some <strong>dynamics</strong> and <strong>observations</strong> to fit the evolution path.</p><p><strong>An Example</strong></p><p>Let's look at a random walk example below,</p><p>Say we model some hidden states with two parts, which are its last state and some random noise. Also, we give the mapping relationship from <span class="math inline">\(x_k\)</span> to <span class="math inline">\(z_k\)</span> as below. <span class="math display">\[ x_k = x_{k - 1} + w_{k - 1}, w_{k} \sim N(0, Q), \]</span></p><p><span class="math display">\[ z_k = x_k + \epsilon_{k}, \epsilon_{k} \sim N(0, R), \]</span></p><p>where <span class="math inline">\(x_k\)</span> is the state variable and <span class="math inline">\(z_k\)</span> is the observation value, and <span class="math inline">\(w_{k}\)</span>, <span class="math inline">\(\epsilon_{k}\)</span> are independent normal random noise.</p><figure><img src="random_walk.png" alt="Random walk"><figcaption>Random walk</figcaption></figure><p>Basically, we have a state space model about <span class="math inline">\(x_k\)</span>, and we would like to know how exactly <span class="math inline">\(x_k\)</span> will evolve in future steps. From the equations above, we can also estimate <span class="math inline">\(\hat x_k\)</span> with current <span class="math inline">\(\hat x_{k - 1}\)</span> and <span class="math inline">\(z_{k-1}\)</span>.</p><p><strong>Probabilistic State Space Models</strong></p><p>But usually, a point estimate is less significant than an interval estimate. So here comes Probabilistic State Space Models.</p><p>With the same example above, we can know the distribution of <span class="math inline">\(x_k\)</span> given <span class="math inline">\(x_{k-1}\)</span>and the distribution of observations <span class="math inline">\(z_k\)</span> given <span class="math inline">\(x_{k}\)</span>. <span class="math display">\[ p(x_k | x_{k - 1}) = \frac{1}{\sqrt{2 \pi Q}}\exp \left( -\frac{1}{2Q}(x_k - x_{k - 1})^2 \right) \]</span></p><p><span class="math display">\[ p(z_k | x_{k}) = \frac{1}{\sqrt{2 \pi R}}\exp \left( -\frac{1}{2R}(z_k - x_{k})^2 \right) \]</span></p><p>where <span class="math inline">\(p(\cdot)\)</span> represents a probability density function.</p><p><strong>Assumptions</strong></p><p>Typically, we use <span class="math inline">\(p(x_k | x_{k - 1})\)</span> instead of <span class="math inline">\(p(x_k | x_{1},x_{2},...,x_{k - 1})\)</span> to describe the conditional distribution is due to the Markovian assumption, which is <strong>future states are independent from the past states given the present.</strong> <span class="math display">\[ p(x_k | x_{k - 1}) = p(x_k | x_{1},x_{2},...,x_{k - 1}, z_{1},z_{2},...,z_{k - 1}) \]</span> Also, we can also naturally think of the relationship between states and observations. Obviously, <strong>observations only depend on its current states</strong> instead of past observations or past states. <span class="math display">\[ p(z_k | x_{k}) = p(z_k | x_{1},x_{2},...,x_{k}, z_{1},z_{2},...,z_{k - 1}) \]</span> Simpler forms of these assumptions are as below <span class="math display">\[ p(x_k | x_{1:k-1}, z_{1:k}) = p(x_k | x_{k - 1}) \]</span></p><p><span class="math display">\[ p(z_k | x_{1:k}, z_{1:k - 1}) = p(z_k | x_{k}) \]</span></p><h3 id="bayesian-filter">1. Bayesian Filter</h3><p>From <a href="https://en.wikipedia.org/wiki/Bayesian_inference" target="_blank" rel="noopener">Bayesian inference</a>, the probability for an event is updated as more evidence or information becomes available, so we would like to use Bayes rules to <strong>simulate</strong> the probability distribution of hidden states <span class="math inline">\(x_t\)</span> with incoming observations. <span class="math display">\[ \begin{align*} p(x_k |z_{1:k}) &amp;= \frac{p(x_k, z_{1:k})}{p( z_{1:k})}\\ &amp;= \frac{p(z_k | z_{1:k-1}, x_k) p(x_k |z_{1:k-1}) p(z_{1:k-1})}{p(z_{1:k})}\\ &amp;= \eta p(z_k | x_k) p(x_k | z_{1:k-1}), \space where \space\space \eta = p(z_k | z_{1:k-1})\\ &amp;= \eta p(z_k | x_k) \int{p(x_k | x_{k-1}, z_{1:k-1})p(x_{k-1} | z_{1:k-1})dx_{k-1}}\\ &amp;= \eta p(z_k | x_k) \int{p(x_k | x_{k-1})p(x_{k-1} | z_{1:k-1})dx_{k-1}}\\ \end{align*} \]</span> Here comes a recursion formula if we replace <span class="math inline">\(p(x_k |u_{1:k})\)</span> with <span class="math inline">\(Bel(x_k)\)</span> meaning the posterior pdf of <span class="math inline">\(x_k\)</span> at time <span class="math inline">\(k\)</span>, so we have <span class="math display">\[ Bel(x_k) = \eta p(z_k|x_k) \int p(x_k|x_{k-1})Bel(x_{k-1})dx_{k-1} \]</span> where <span class="math inline">\(p(z_k|x_k)\)</span> and <span class="math inline">\(p(x_k|x_{k-1})\)</span> correspond exactly to the 2 hypothetical equations discussed in the random walk example, which are <strong>Observations-States Mapping</strong> and <strong>State Dynamics</strong>. Intuitively, we need state dynamics to make apriori estimates (<span class="math inline">\(\int{p(x_k | x_{k-1})p(x_{k-1} | z_{1:k-1})dx_{k-1}}\)</span>) and observations to make likelihood adjustments, thus making the Bayesian rules complete. <a href="https://users.aalto.fi/~ssarkka/course_k2016/handout3.pdf#page=12" target="_blank" rel="noopener">Here</a> shows how the distribution of <span class="math inline">\(x_{k}\)</span> evolves under Bayesian rules.</p><p><strong>A New Input</strong></p><p>Now we introduce another control variable <span class="math inline">\({u_t}\)</span> which may serve as an additional impact to <span class="math inline">\(x_k\)</span>, and we can now imagine the state model has the new form like below: <span class="math display">\[ x_k = x_{k - 1} + u_{k} + w_{k - 1}, w_{k} \sim N(0, Q), \]</span></p><p><span class="math display">\[ z_k = x_k + \epsilon_{k}, \epsilon_{k} \sim N(0, R), \]</span></p><p>Also, we cast those 2 assumptions to <span class="math inline">\(u_k\)</span>, then we have <span class="math display">\[ p(x_k | x_{1:k-1}, u_{1:k}, z_{1:k}) = p(x_k | x_{k - 1}, u_k) \]</span></p><p><span class="math display">\[ p(z_k | x_{1:k}, u_{1:k}, z_{:k - 1}) = p(z_k | x_{k}) \]</span></p><p>The target conditional probability distribution has now become posterior distribution <span class="math inline">\(p(x_k | u_{1:k}, z_{1:k})\)</span>, we would like to know how the current state behaves given the most recent series of observations and control variables. <span class="math display">\[ \begin{align*} p(x_k |u_{1:k}, z_{1:k}) &amp;= \frac{p(x_k, u_{1:k}, z_{1:k})}{p(u_{1:k}, z_{1:k})}\\ &amp;= \frac{p(z_k | u_{1:k}, z_{1:k-1}, x_k) p(x_k | u_{1:k}, z_{1:k-1}) p(u_{1:k}, z_{1:k-1})}{p(u_{1:k}, z_{1:k})}\\ &amp;= \eta p(z_k | x_k) p(x_k | u_{1:k}, z_{1:k-1}), \space where \space\space \eta = p(z_k | u_{1:k}, z_{1:k-1})\\ &amp;= \eta p(z_k | x_k) \int{p(x_k | x_{k-1}, u_{1:k}, z_{1:k-1})p(x_{k-1} | u_{1:k}, z_{1:k-1})dx_{k-1}}\\ &amp;= \eta p(z_k | x_k) \int{p(x_k | x_{k-1}, u_k)p(x_{k-1} | u_{1:k-1}, z_{1:k-1})dx_{k-1}}\\ \end{align*} \]</span> Here comes a recursion formula if we replace <span class="math inline">\(p(x_k |u_{1:k}, z_{1:k})\)</span> with <span class="math inline">\(Bel(x_k)\)</span> meaning the posterior pdf of <span class="math inline">\(x_k\)</span> at time <span class="math inline">\(k\)</span>, so we have <span class="math display">\[ Bel(x_k) = \eta p(z_k|x_k) \int p(x_k|x_{k-1},u_k)Bel(x_{k-1})dx_{k-1} \]</span> which is all the same as the previous formula except <span class="math inline">\(u_k\)</span>. Now we can separate this recursion formula into two parts <span class="math display">\[ \overline {Bel}{(x_k)} = \int p(x_k|x_{k-1},u_k)Bel(x_{k-1})dx_{k-1} \]</span></p><p><span class="math display">\[ Bel(x_k) = \eta p(z_k|x_k)\overline {Bel}{(x_k)} \]</span></p><p>state prediction and state update respectively. We can say <span class="math inline">\(x_k\)</span> is predicted with new inputs of control variables <span class="math inline">\(u_k\)</span> and updated with corresponding observations <span class="math inline">\(z_k\)</span>.</p><p>Why we need a new input <span class="math inline">\(u_k\)</span>? Simply speaking, we need some other factors rather than pure past states to explain the evolution of <span class="math inline">\(x_k\)</span>. To be more specific, Bayesian filter is widely used in probabilistic robotics where there is always robotics control (say robots are controlled to move 2 meters ahead) and the control itself influences a system's state (the state is the position of the robot).</p><h3 id="kalman-filter-1">2. Kalman Filter</h3><p>The recursion equation above indicates how the distribution of <span class="math inline">\(x_k\)</span> evolves through time. However we do not know what is the exact distribution of <span class="math inline">\(x_{k-1}\)</span> given a random initial distribution <span class="math inline">\(x_0\)</span>. If an initial random distribution is given, then we must follow the recursion formula to integrate over all possible <span class="math inline">\(x_{k-1}\)</span> to get an estimate.</p><p>Here comes the trick of Kalman Filter-using <strong>Gaussian</strong> distributions to describe <span class="math inline">\(x_k\)</span>. Because linear combinations of Gaussian distributions are still Gaussian, the states distribution evolution is easier to follow under Gaussian assumptions.</p><p><strong>Assumptions</strong></p><ol type="1"><li>State Dynamics and Observation-State Mapping are both linear models:</li></ol><p><span class="math display">\[ x_k = F_k x_{k-1} + B_ku_k + w_k \]</span></p><p><span class="math display">\[ z_k = H_k x_{k} + \epsilon_k \]</span></p><ol start="2" type="1"><li>State noise <span class="math inline">\(w_t\)</span> and observation noise <span class="math inline">\(\epsilon_t\)</span> both follow normal distribution:</li></ol><p><span class="math display">\[ w_{k} \sim N(0, Q_k) \]</span></p><p><span class="math display">\[ \epsilon_{k} \sim N(0, R_k) \]</span></p><p>Also, we introduce <span class="math inline">\(P_k = Var(x_k - \hat x_{k|k - 1})\)</span> to describe the variance of estimate error (which is the difference between actual state <span class="math inline">\(x_k\)</span> and estimate state <span class="math inline">\(\hat x_{k|k-1}\)</span>).</p><p><strong>Kalman Filter Derivation</strong></p><p>We follow the <strong>state prediction</strong> and <strong>state update</strong> procedure as above to derive <span class="math inline">\(x_k\)</span> and <span class="math inline">\(P_k\)</span></p><ol type="1"><li>State Prediction (Arrive at Apriori Estimate):</li></ol><p><span class="math display">\[ \hat x_{k|k-1} = F_{k} \hat x_{k-1|k-1} + B_k u_k + w_k \]</span></p><p><span class="math display">\[ \begin {align*} P_{k|k-1} &amp;= Var(x_{k} - \hat x_{k|k-1}) \\ &amp;= Var(F_k(x_{k} - \hat x_{k|k-1}) + w_k) \\ &amp;= F_k P_k F_k^T + Q_k \end {align*} \]</span></p><ol start="2" type="1"><li><p>State Update (Obtain the Posteriori Estimate): <span class="math display">\[ K_k = P_{k|k-1}H_k^T(H_k P_{k|k-1} H_k^T + R_k)^{-1} \]</span></p><p><span class="math display">\[ \hat x_{k|k} = \hat x_{k|k-1} + K_k (z_k - H_k \hat x_{k|k-1}) \]</span></p><p><span class="math display">\[ P_{k|k} = [I - K H_k] P_{k|k-1} \]</span></p><p><span class="math inline">\(K\)</span> for <strong>Kalman Gain</strong> is how Kalman Filters extends from Bayesian Filter. Let's first look at the state update which can be interpreted as <strong>apriori estimate</strong> plus a portion of <strong>predicted observation error</strong>.</p><p>Let's then understand the structure of <span class="math inline">\(K\)</span>, where <span class="math display">\[ Var(z_k - \hat z_{k|k-1}) = Var(H_k(x_k - \hat x_{k|k-1}) + \epsilon_k) = H_k P_{k|k-1} H_k^T + R_k \]</span> So we can express the portion of predicted observation error as <span class="math display">\[ K_k (z_k - \hat z_{k|k-1}) = Var[x_k - x_{k|k-1}] H^T_k Var^{-1}[z_k - \hat z_{k|k-1}] (z_k - \hat z_{k|k-1}) \]</span> We can interpret <span class="math inline">\(K\)</span> as a compensation term for model prediction uncertainty.</p><p>A large <span class="math inline">\(K\)</span> means there is much more noise in state prediction (a relatively larger <span class="math inline">\(P_{k|k-1}\)</span>) than in observation prediction (a relatively smaller <span class="math inline">\(Var(z_k - \hat z_{k|k-1})\)</span>), then we apply a large correction term to apriori estimate <span class="math inline">\(\hat x_{k|k-1}\)</span> to approximate a more accurate posteriori <span class="math inline">\(x_{k|k}\)</span>. Otherwise, a small <span class="math inline">\(K\)</span> means the current prediction <span class="math inline">\(\hat x_{k|k-1}\)</span> makes some sense so that a small correction is needed.</p><p>How is <span class="math inline">\(K\)</span> derived exactly? Follow the interpretation of <span class="math inline">\(K\)</span>, we can think of <span class="math inline">\(K\)</span> must be the result of minimizing the state prediction error <span class="math inline">\(P_{k|k}\)</span>. So let's express <span class="math inline">\(P_{k|k}\)</span> as below <span class="math display">\[ \begin {align*} P_{k|k} &amp;= Var(x_k - \hat x_{k|k}) = Var(x_k - [\hat x_{k|k-1} + K_k (z_k - H_k \hat x_{k|k-1})]) \\ &amp;= Var(x_k - [\hat x_{k|k-1} + K_k (H_k x_{k} + \epsilon_k - H_k \hat x_{k|k-1})]) \\ &amp;= Var(x_k - \hat x_{k|k-1} - K_k H_k(x_{k} - \hat x_{k|k-1}) - K_k\epsilon_k ) \\ &amp;= Var((I - K_k H_k)(x_{k} - \hat x_{k|k-1})) + Var(K_k\epsilon_k ) \\ &amp;= (I - K_k H_k)P_{k|k-1}(I - K_k H_k)^T + K_k R_k K_k^T\\ \end {align*} \]</span> Now we introduce <span class="math inline">\(S_k = Var(z_k - \hat z_{k|k-1}) = H_k P_{k|k-1} H_k^T + R_k\)</span>, then we have <span class="math display">\[ P_{k|k} = P_{k|k-1} - K_k H_k P_{k|k-1} - P_{k|k-1}H_k^T K_k^T + K_k S_k K_k^T \]</span> Now minimize the trace of <span class="math inline">\(P_{k|k}\)</span> to minimize the squared error, so we have <span class="math display">\[ \frac{\partial tr(P_{k|k})}{\partial K_k} = -2P_{k|k-1} H_k^T + 2K_k S_k = 0 \]</span> then we get <span class="math inline">\(K_k = P_{k|k-1} H_k^T S_k^{-1}\)</span></p></li></ol><p><strong>Kalman Filter Bayesian Derivation</strong></p><p>We stick to the recursion formula derived by Bayesian rules: <span class="math display">\[ Bel(x_k) = \eta p(z_k|x_k) \int p(x_k|x_{k-1},u_k) Bel(x_{k-1})dx_{k-1} \]</span> Let's give an initial condition <span class="math inline">\(Bel(x_0) = N(x_0, P_0)\)</span>, then for <span class="math inline">\(k=1\)</span> with state dynamics <span class="math inline">\(x_k = F_k x_{k-1} + B_k u_k + w_k\)</span>, we know <span class="math inline">\(p(x_1|x_{0},u_1) = N(F_1 x_0 + B_1 u_1, Q_1)\)</span>.</p><p>According to <a href="https://users.aalto.fi/~ssarkka/course_k2016/handout3.pdf#page=14" target="_blank" rel="noopener">convolution rules</a> in Gaussian distribution, we can get <span class="math display">\[ \overline {Bel}(x_1) = N(F_1 x_0 + B_1 u_1, F_1 P_0 F_1^T + Q_1) \]</span> The same goes for any other <span class="math inline">\(k\geq 1\)</span> as the recursion holds true for growing <span class="math inline">\(k\)</span>, which is <span class="math display">\[ \overline {Bel}(x_k) = N(F_k x_{k-1} + B_k u_k, F_k P_{k-1} F_k^T + Q_k) \]</span> For the observation-state mapping part, we know <span class="math inline">\(p(z_k|x_k) = N(H_k x_k, R_t)\)</span>, so the problem now becomes computing the distribution of 2 Gaussian variables. This will definitely lead to the same results above like <span class="math display">\[ \eta N(H_k x_k, R_t) N(F_k x_{k-1} + B_k u_k, F_k P_{k-1} F_k^T + Q_k) \\ = N(F_k x_{k-1} + B_k u_k + K_k (z_k - H_k (F_k x_{k-1} + B_k u_k)), [I - K H_k] P_{k|k-1}) \]</span> for now I have no idea how this can be derived rigorously, but <a href="http://www.tina-vision.net/docs/memos/2003-003.pdf" target="_blank" rel="noopener">P.A. Bromiley, Products and Convolutions of Gaussian Probability Density Functions</a> introduces deriving distribution of the product of n univariate Gaussian variables.</p><p><strong>Reference</strong>:</p><p>[1] <a href="https://www.cnblogs.com/ycwang16/p/5999034.html" target="_blank" rel="noopener">细说Kalman滤波：The Kalman Filter</a></p><p>[2] <a href="https://users.aalto.fi/~ssarkka/course_k2016/handout3.pdf" target="_blank" rel="noopener">Simo Särkkä, Bayesian Filtering Equations and Kalman Filter</a></p><p>[3] <a href="http://www.cs.cmu.edu/~16831-f14/notes/F14/16831_lecture02_prayana_tdecker_humphreh.pdf" target="_blank" rel="noopener">Statistical Techniques in Robotics (16-831, F10) Lecture #02 (Thursday, August 28)Bayes Filtering</a></p><p>[4] <a href="http://people.ciirc.cvut.cz/~hlavac/TeachPresEn/55AutonomRobotics/2015-05-04ReinsteinBayes-ekf.pdf" target="_blank" rel="noopener">Michal Reinštein, From Bayes to Extended Kalman Filter</a></p></div></div><nav class="post-pagination"><span class="page-number"></span> <a class="older-posts" href="/2019/10/20/CCA/">Next post<br>Canonical Component Analysis</a></nav></div></div><div class="single-column-footer">Proudly published with Hexo<br>Theme <a href="https://github.com/SumiMakito/hexo-theme-journal/" target="_blank" rel="noreferrer noopener">Journal.</a> by <a href="https://mak1t0.cc/" target="_blank" rel="noreferrer noopener">Makito</a><br>&copy; 2020 <a href="http://yoursite.com">Avalon</a></div></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.14.4/dist/umd/popper.min.js" integrity="sha256-EGs9T1xMHdvM1geM8jPpoo8EZ1V1VRsmcJz8OByENLA=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/vue@2.5.17/dist/vue.min.js" integrity="sha256-FtWfRI+thWlNz2sB3SJbwKx5PgMyKIVgwHCTwa3biXc=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/smooth-scroll@14.2.1/dist/smooth-scroll.polyfills.min.js" integrity="sha256-CI4Gq5E0io1Pv0xM3qPM+NUIOhbIBvC3GiN1Y4KhXpw=" crossorigin="anonymous"></script><script src="/js/journal.js?88474885"></script></body></html>